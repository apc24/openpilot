#!/usr/bin/env python3
"""
E2E (End-to-End) è‡ªå‹•é‹è»¢ãƒ¢ãƒ‡ãƒ«å®Ÿè¡Œãƒ‡ãƒ¼ãƒ¢ãƒ³

ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€å­¦ç¿’æ¸ˆã¿E2Eãƒ¢ãƒ‡ãƒ«ã‚’OpenPilotã®å®Ÿè¡Œç’°å¢ƒã§å‹•ä½œã•ã›ã‚‹ãŸã‚ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã§ã™ã€‚

ä¸»ãªæ©Ÿèƒ½:
- ã‚«ã‚¹ã‚¿ãƒ å­¦ç¿’æ¸ˆã¿ONNXãƒ¢ãƒ‡ãƒ«ã®æ¨è«–å®Ÿè¡Œ
- ã‚«ãƒ¡ãƒ©ç”»åƒã€è»Šä¸¡çŠ¶æ…‹ã€ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±ã®å‰å‡¦ç†
- E2Eåˆ¶å¾¡ä¿¡å·ï¼ˆåŠ é€Ÿåº¦ã€ã‚¹ãƒ†ã‚¢ãƒªãƒ³ã‚°ï¼‰ã®å‡ºåŠ›
- OpenPilotãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã¨ã®çµ±åˆ

ä½¿ç”¨æ–¹æ³•:
python selfdrive/modeld/e2emodeld.py [--demo]

ç’°å¢ƒå¤‰æ•°:
- SEND_RAW_PRED: ç”Ÿã®äºˆæ¸¬å€¤ã‚’é€ä¿¡ã™ã‚‹ã‹ã©ã†ã‹
- SEND_E2E_OUTPUT: E2Eå‡ºåŠ›ã‚’é€ä¿¡ã™ã‚‹ã‹ã©ã†ã‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1ï¼‰
"""

import os
import time
import pickle
import numpy as np
import cv2
import cereal.messaging as messaging
from cereal import car, log
from pathlib import Path
from typing import Dict, Optional
from setproctitle import setproctitle
from cereal.messaging import PubMaster, SubMaster
from cereal.visionipc import VisionIpcClient, VisionStreamType, VisionBuf
from openpilot.common.swaglog import cloudlog
from openpilot.common.params import Params
from openpilot.common.filter_simple import FirstOrderFilter
from openpilot.common.realtime import config_realtime_process
from openpilot.common.transformations.model import get_warp_matrix
from openpilot.selfdrive import sentry
from openpilot.selfdrive.car.car_helpers import get_demo_car_params
from openpilot.selfdrive.controls.lib.desire_helper import DesireHelper
from openpilot.selfdrive.modeld.runners import ModelRunner, Runtime
from openpilot.selfdrive.modeld.parse_model_outputs import Parser
from openpilot.selfdrive.modeld.constants import ModelConstants
from openpilot.selfdrive.modeld.models.commonmodel_pyx import ModelFrame, CLContext

# ===== ãƒ—ãƒ­ã‚»ã‚¹è¨­å®š =====
PROCESS_NAME = "selfdrive.modeld.e2emodeld"
SEND_RAW_PRED = os.getenv('SEND_RAW_PRED')                    # ãƒ‡ãƒãƒƒã‚°ç”¨: ç”Ÿã®äºˆæ¸¬å€¤é€ä¿¡ãƒ•ãƒ©ã‚°
SEND_E2E_OUTPUT = os.getenv('SEND_E2E_OUTPUT', '1')          # E2Eå‡ºåŠ›ã‚’å¸¸ã«é€ä¿¡ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæœ‰åŠ¹ï¼‰

# ===== ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹è¨­å®š =====
# ã‚«ã‚¹ã‚¿ãƒ å­¦ç¿’æ¸ˆã¿E2Eãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹è¨­å®šï¼ˆepoch 19 æœ€æ–°ç‰ˆï¼‰
MODEL_PATHS = {
  ModelRunner.THNEED: Path(__file__).parent / 'models/checkpoint_epoch_19_best.thneed',  # GPUæœ€é©åŒ–ç‰ˆï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
  ModelRunner.ONNX: Path(__file__).parent / 'models/checkpoint_epoch_19_best.onnx'       # æ¨™æº–ONNXç‰ˆ
}

# ãƒ¢ãƒ‡ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆå…¥åŠ›/å‡ºåŠ›å½¢çŠ¶æƒ…å ±ã‚’å«ã‚€ï¼‰
METADATA_PATH = Path(__file__).parent / 'models/supercombo_metadata.pkl'

# ===== ãƒ¢ãƒ‡ãƒ«å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š =====
DEFAULT_CAR_STATE_DIM = 8      # è»Šä¸¡çŠ¶æ…‹ãƒ™ã‚¯ã‚¿ãƒ¼ã®æ¬¡å…ƒæ•°ï¼ˆé€Ÿåº¦ã€åŠ é€Ÿåº¦ã€è§’åº¦ãªã©ï¼‰
DEFAULT_NAV_VECTOR_DIM = 150   # ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ãƒ™ã‚¯ã‚¿ãƒ¼ã®æ¬¡å…ƒæ•°
DEFAULT_IMAGE_SIZE = 224       # å…¥åŠ›ç”»åƒã‚µã‚¤ã‚ºï¼ˆ224x224ãƒ”ã‚¯ã‚»ãƒ«ï¼‰

# ===== E2Eå‡¦ç†é »åº¦è¨­å®š =====
E2E_MODEL_FREQ = 10.0          # E2Eãƒ¢ãƒ‡ãƒ«å®Ÿè¡Œé »åº¦: 10Hzï¼ˆè² è·è»½æ¸›ã®ãŸã‚ï¼‰

# ===== ç”»åƒå‰å‡¦ç†è¨­å®šï¼ˆImageNetæ¨™æº–ã«æº–æ‹ ï¼‰=====
IMAGE_SIZE = 224                                                    # å…¥åŠ›ç”»åƒã‚µã‚¤ã‚º
IMAGENET_MEAN = np.array([0.485, 0.456, 0.406], dtype=np.float32)  # ImageNetå¹³å‡å€¤ï¼ˆRGBé †ï¼‰
IMAGENET_STD = np.array([0.229, 0.224, 0.225], dtype=np.float32)   # ImageNetæ¨™æº–åå·®ï¼ˆRGBé †ï¼‰

def load_model_config() -> Dict[str, int]:
  """
  ãƒ¢ãƒ‡ãƒ«è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å…¥åŠ›æ¬¡å…ƒã‚’èª­ã¿è¾¼ã¿
  
  ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ã€ãã“ã‹ã‚‰å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«å…¥åŠ›æ¬¡å…ƒã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚
  ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚
  
  Returns:
    Dict[str, int]: ãƒ¢ãƒ‡ãƒ«å…¥åŠ›æ¬¡å…ƒã®è¾æ›¸
      - car_state_dim: è»Šä¸¡çŠ¶æ…‹ãƒ™ã‚¯ã‚¿ãƒ¼ã®æ¬¡å…ƒæ•°
      - nav_vector_dim: ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ãƒ™ã‚¯ã‚¿ãƒ¼ã®æ¬¡å…ƒæ•°  
      - image_size: å…¥åŠ›ç”»åƒã®ã‚µã‚¤ã‚ºï¼ˆæ­£æ–¹å½¢ï¼‰
  """
  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§åˆæœŸåŒ–
  config = {
    'car_state_dim': DEFAULT_CAR_STATE_DIM,
    'nav_vector_dim': DEFAULT_NAV_VECTOR_DIM,
    'image_size': DEFAULT_IMAGE_SIZE
  }
  
  try:
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã¿
    if METADATA_PATH.exists():
      with open(METADATA_PATH, 'rb') as f:
        metadata = pickle.load(f)
        
      # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«å…¥åŠ›æ¬¡å…ƒæƒ…å ±ãŒã‚ã‚Œã°æ›´æ–°
      if 'input_shapes' in metadata:
        input_shapes = metadata['input_shapes']
        # å„å…¥åŠ›ã®æœ€å¾Œã®æ¬¡å…ƒã‚’å–å¾—ï¼ˆãƒãƒƒãƒæ¬¡å…ƒã‚’é™¤ãï¼‰
        if 'carState' in input_shapes:
          config['car_state_dim'] = input_shapes['carState'][-1]  # æœ€å¾Œã®æ¬¡å…ƒ
        if 'navVector' in input_shapes:
          config['nav_vector_dim'] = input_shapes['navVector'][-1]  # æœ€å¾Œã®æ¬¡å…ƒ
        if 'mainCamera' in input_shapes:
          config['image_size'] = input_shapes['mainCamera'][-1]  # H=Wï¼ˆæ­£æ–¹å½¢ç”»åƒï¼‰
          
      cloudlog.info(f"Model config loaded from metadata: {config}")
    else:
      cloudlog.warning(f"Metadata file not found, using defaults: {config}")
      
  except Exception as e:
    cloudlog.error(f"Error loading model config: {e}, using defaults")
    
  return config

# E2Eå°‚ç”¨ã®æ›´æ–°é »åº¦ï¼ˆè² è·ãƒãƒ©ãƒ³ã‚¹ã®ãŸã‚10Hzã«æˆ»ã™ï¼‰
E2E_MODEL_FREQ = 10.0  # 10Hzï¼ˆè² è·è»½æ¸›ã®ãŸã‚ï¼‰

# ç”»åƒå‰å‡¦ç†ã®è¨­å®š
IMAGE_SIZE = 224
IMAGENET_MEAN = np.array([0.485, 0.456, 0.406], dtype=np.float32)
IMAGENET_STD = np.array([0.229, 0.224, 0.225], dtype=np.float32)

def process_camera_frame(buf: VisionBuf, transform_matrix: np.ndarray) -> np.ndarray:
  """
  VisionBufã‹ã‚‰å®Ÿéš›ã®ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€E2Eãƒ¢ãƒ‡ãƒ«ç”¨ã«å‰å‡¦ç†ã‚’å®Ÿè¡Œ
  
  å‰å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—:
  1. YUV420ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‹ã‚‰RGBã¸å¤‰æ›
  2. 224x224ãƒ”ã‚¯ã‚»ãƒ«ã«ãƒªã‚µã‚¤ã‚º
  3. [0,255] â†’ [0,1] æ­£è¦åŒ–
  4. ImageNetæ¨™æº–æ­£è¦åŒ–ï¼ˆå¹³å‡å€¤æ¸›ç®—ã€æ¨™æº–åå·®é™¤ç®—ï¼‰
  5. HWC â†’ CHWå½¢å¼å¤‰æ›ï¼ˆPyTorchãƒ¢ãƒ‡ãƒ«äº’æ›ï¼‰
  6. ãƒãƒƒãƒæ¬¡å…ƒè¿½åŠ 
  
  Args:
    buf: VisionBuf - ã‚«ãƒ¡ãƒ©ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ï¼ˆYUV420å½¢å¼ï¼‰
    transform_matrix: np.ndarray - å¤‰æ›è¡Œåˆ—ï¼ˆç¾åœ¨æœªä½¿ç”¨ï¼‰
    
  Returns:
    np.ndarray: å‰å‡¦ç†æ¸ˆã¿ç”»åƒãƒ†ãƒ³ã‚½ãƒ« (1, 3, 224, 224)
      - shape: (batch_size=1, channels=3, height=224, width=224)
      - dtype: float32
      - range: ImageNetæ­£è¦åŒ–å¾Œã®å€¤åŸŸ
  """
  try:
    # VisionBufã®æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯
    if buf is None:
      cloudlog.warning("VisionBuf is None, using dummy image")
      return np.zeros((1, 3, IMAGE_SIZE, IMAGE_SIZE), dtype=np.float32)
    
    # Step 1: VisionBufã®ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’å–å¾— (YUV420å½¢å¼)
    # YUV420: Y(è¼åº¦) + U/V(è‰²å·®)ãŒç¸¦æ–¹å‘ã«1.5å€ã®ã‚µã‚¤ã‚ºã§æ ¼ç´
    print("buf.width =", buf.width)
    print("buf.height =", buf.height)
    print("len(buf.data) =", len(buf.data))
    yuv_img = np.frombuffer(buf.data, dtype=np.uint8).reshape((buf.height + buf.height//2, buf.width))
    
    # Step 2: YUV420ã‚’RGBã«å¤‰æ›ï¼ˆOpenCVã‚’ä½¿ç”¨ï¼‰
    rgb_img = cv2.cvtColor(yuv_img, cv2.COLOR_YUV2RGB_I420)
    
    # Step 3: ç”»åƒã®ãƒªã‚µã‚¤ã‚º (å…ƒè§£åƒåº¦ â†’ 224x224)
    resized_img = cv2.resize(rgb_img, (IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_LINEAR)
    
    # Step 4: [0, 255] â†’ [0, 1] æ­£è¦åŒ–
    normalized_img = resized_img.astype(np.float32) / 255.0
    
    # Step 5: ImageNetæ¨™æº–æ­£è¦åŒ– (training.pyã¨åŒã˜å‰å‡¦ç†)
    # å„ãƒãƒ£ãƒ³ãƒãƒ«ï¼ˆR,G,Bï¼‰ã«å¯¾ã—ã¦ (pixel - mean) / std
    for i in range(3):
      normalized_img[:, :, i] = (normalized_img[:, :, i] - IMAGENET_MEAN[i]) / IMAGENET_STD[i]
    
    # Step 6: HWC â†’ CHW (Height, Width, Channel â†’ Channel, Height, Width)
    # PyTorchãƒ¢ãƒ‡ãƒ«ã®å…¥åŠ›å½¢å¼ã«å¤‰æ›
    chw_img = np.transpose(normalized_img, (2, 0, 1))
    
    # Step 7: ãƒãƒƒãƒæ¬¡å…ƒã‚’è¿½åŠ  (C, H, W) â†’ (1, C, H, W)
    batch_img = chw_img[np.newaxis, :]
    
    # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°: å‰å‡¦ç†çµæœã®æ¦‚è¦ã‚’å‡ºåŠ›
    cloudlog.debug(f"Camera frame processed: {buf.width}x{buf.height} â†’ {IMAGE_SIZE}x{IMAGE_SIZE}, range: [{batch_img.min():.3f}, {batch_img.max():.3f}]")
    return batch_img
    
  except Exception as e:
    cloudlog.error(f"Error processing camera frame: {e}")
    # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ã‚¼ãƒ­ã§åŸ‹ã‚ãŸãƒ€ãƒŸãƒ¼ç”»åƒã‚’è¿”ã™
    return np.zeros((1, 3, IMAGE_SIZE, IMAGE_SIZE), dtype=np.float32)

def process_car_state(car_state_data: Dict, target_dim: int = 8) -> np.ndarray:
  """
  è»Šä¸¡çŠ¶æ…‹ãƒ‡ãƒ¼ã‚¿ã‚’å‰å‡¦ç†ã—ã¦E2Eãƒ¢ãƒ‡ãƒ«å…¥åŠ›å½¢å¼ã«å¤‰æ›
  
  è»Šä¸¡çŠ¶æ…‹ã«ã¯ä»¥ä¸‹ã®æƒ…å ±ãŒå«ã¾ã‚Œã¾ã™:
  - é€Ÿåº¦ (vEgo): m/s
  - åŠ é€Ÿåº¦ (aEgo): m/sÂ²  
  - ã‚¹ãƒ†ã‚¢ãƒªãƒ³ã‚°è§’åº¦ (steeringAngleDeg): åº¦
  - ãƒ¨ãƒ¼è§’é€Ÿåº¦ (yawRate): rad/s
  - ã‚¦ã‚¤ãƒ³ã‚«ãƒ¼çŠ¶æ…‹ (leftBlinker, rightBlinker): boolean
  - ãƒšãƒ€ãƒ«çŠ¶æ…‹ (brakePressed, gasPressed): boolean
  
  Args:
    car_state_data: Dict - carStateãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‡ãƒ¼ã‚¿
    target_dim: int - å‡ºåŠ›æ¬¡å…ƒæ•°ï¼ˆãƒ¢ãƒ‡ãƒ«ã®æœŸå¾…ã™ã‚‹å…¥åŠ›æ¬¡å…ƒï¼‰
    
  Returns:
    np.ndarray: å‰å‡¦ç†æ¸ˆã¿è»Šä¸¡çŠ¶æ…‹ãƒ™ã‚¯ã‚¿ãƒ¼ (1, target_dim)
      - æ­£è¦åŒ–æ¸ˆã¿ï¼ˆä¸»è¦ãªå€¤ã¯[-1, 1]ç¯„å›²ï¼‰
      - ä¸è¶³ã™ã‚‹æ¬¡å…ƒã¯ã‚¼ãƒ­ã§åŸ‹ã‚ã‚‹
  """
  try:
    # æŒ‡å®šã•ã‚ŒãŸæ¬¡å…ƒæ•°ã§ã‚¼ãƒ­åˆæœŸåŒ–
    car_state_input = np.zeros(target_dim, dtype=np.float32)
    
    if car_state_data is not None:
      # åŸºæœ¬çš„ãªè»Šä¸¡çŠ¶æ…‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŠ½å‡ºãƒ»é…åˆ—åŒ–
      state_values = [
        getattr(car_state_data, 'vEgo', 0.0),           # 0: é€Ÿåº¦ (m/s)
        getattr(car_state_data, 'aEgo', 0.0),           # 1: åŠ é€Ÿåº¦ (m/sÂ²)
        getattr(car_state_data, 'steeringAngleDeg', 0.0), # 2: ã‚¹ãƒ†ã‚¢ãƒªãƒ³ã‚°è§’åº¦ (deg)
        getattr(car_state_data, 'yawRate', 0.0),        # 3: ãƒ¨ãƒ¼è§’é€Ÿåº¦ (rad/s)
        getattr(car_state_data, 'leftBlinker', 0.0),    # 4: å·¦ã‚¦ã‚¤ãƒ³ã‚«ãƒ¼ (0/1)
        getattr(car_state_data, 'rightBlinker', 0.0),   # 5: å³ã‚¦ã‚¤ãƒ³ã‚«ãƒ¼ (0/1)
        getattr(car_state_data, 'brakePressed', 0.0),   # 6: ãƒ–ãƒ¬ãƒ¼ã‚­ (0/1)
        getattr(car_state_data, 'gasPressed', 0.0),     # 7: ã‚¢ã‚¯ã‚»ãƒ« (0/1)
      ]
      
      # target_dimã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¨­å®šï¼ˆä½™åˆ†ãªãƒ‡ãƒ¼ã‚¿ã¯åˆ‡ã‚Šæ¨ã¦ï¼‰
      actual_len = min(len(state_values), target_dim)
      car_state_input[:actual_len] = state_values[:actual_len]
      
      # ä¸»è¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ­£è¦åŒ–ï¼ˆå­¦ç¿’æ™‚ã¨åŒã˜ã‚¹ã‚±ãƒ¼ãƒ«ã«åˆã‚ã›ã‚‹ï¼‰
      if target_dim > 0:
        car_state_input[0] = np.clip(car_state_input[0] / 50.0, -1.0, 1.0)  # é€Ÿåº¦: 50m/såŸºæº–ã§æ­£è¦åŒ–
      if target_dim > 1:
        car_state_input[1] = np.clip(car_state_input[1] / 5.0, -1.0, 1.0)   # åŠ é€Ÿåº¦: 5m/sÂ²åŸºæº–ã§æ­£è¦åŒ–
      if target_dim > 2:
        car_state_input[2] = np.clip(car_state_input[2] / 180.0, -1.0, 1.0) # è§’åº¦: 180åº¦åŸºæº–ã§æ­£è¦åŒ–
    
    # ãƒãƒƒãƒæ¬¡å…ƒã‚’è¿½åŠ ã—ã¦è¿”ã™
    return car_state_input.reshape(1, target_dim)
    
  except Exception as e:
    cloudlog.error(f"Error processing car state: {e}")
    # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ã‚¼ãƒ­ãƒ™ã‚¯ã‚¿ãƒ¼ã‚’è¿”ã™
    return np.zeros((1, target_dim), dtype=np.float32)

def process_nav_vector(nav_features: np.ndarray, target_dim: int = 150) -> np.ndarray:
  """
  ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ãƒ™ã‚¯ã‚¿ãƒ¼ã‚’å‰å‡¦ç†ã—ã¦E2Eãƒ¢ãƒ‡ãƒ«å…¥åŠ›å½¢å¼ã«å¤‰æ›
  
  ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±ã«ã¯ä»¥ä¸‹ãŒå«ã¾ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™:
  - ç›®çš„åœ°ã¾ã§ã®è·é›¢ã¨æ–¹å‘
  - é“è·¯ç¨®åˆ¥ï¼ˆé«˜é€Ÿé“è·¯ã€ä¸€èˆ¬é“ãªã©ï¼‰
  - äº¤é€šè¦åˆ¶æƒ…å ±
  - ãƒ«ãƒ¼ãƒˆäºˆæ¸¬ãƒ‡ãƒ¼ã‚¿
  - åœ°å›³ç‰¹å¾´é‡
  
  Args:
    nav_features: np.ndarray - ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ç‰¹å¾´é‡
    target_dim: int - å‡ºåŠ›æ¬¡å…ƒæ•°ï¼ˆãƒ¢ãƒ‡ãƒ«ã®æœŸå¾…ã™ã‚‹å…¥åŠ›æ¬¡å…ƒï¼‰
    
  Returns:
    np.ndarray: å‰å‡¦ç†æ¸ˆã¿ãƒŠãƒ“ãƒ™ã‚¯ã‚¿ãƒ¼ (1, target_dim)
      - å€¤ã¯[-1, 1]ç¯„å›²ã«ã‚¯ãƒªãƒƒãƒ—
      - ä¸è¶³ã™ã‚‹æ¬¡å…ƒã¯ã‚¼ãƒ­ã§åŸ‹ã‚ã‚‹
  """
  try:
    # æŒ‡å®šã•ã‚ŒãŸæ¬¡å…ƒæ•°ã§ã‚¼ãƒ­åˆæœŸåŒ–
    nav_vector_input = np.zeros(target_dim, dtype=np.float32)
    
    if nav_features is not None and len(nav_features) > 0:
      # å…¥åŠ›ç‰¹å¾´é‡ã‚’æŒ‡å®šæ¬¡å…ƒæ•°ã¾ã§è¨­å®šï¼ˆä½™åˆ†ãªãƒ‡ãƒ¼ã‚¿ã¯åˆ‡ã‚Šæ¨ã¦ï¼‰
      nav_len = min(len(nav_features), target_dim)
      nav_vector_input[:nav_len] = nav_features[:nav_len]
      
      # å€¤ã®ç¯„å›²ã‚’åˆ¶é™ï¼ˆç•°å¸¸å€¤å¯¾ç­–ã¨å­¦ç¿’æ™‚ã®å‰å‡¦ç†ã¨ã®æ•´åˆæ€§ï¼‰
      nav_vector_input = np.clip(nav_vector_input, -1.0, 1.0)
    
    # ãƒãƒƒãƒæ¬¡å…ƒã‚’è¿½åŠ ã—ã¦è¿”ã™
    return nav_vector_input.reshape(1, target_dim)
    
  except Exception as e:
    cloudlog.error(f"Error processing nav vector: {e}")
    # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ã‚¼ãƒ­ãƒ™ã‚¯ã‚¿ãƒ¼ã‚’è¿”ã™
    return np.zeros((1, target_dim), dtype=np.float32)

class FrameMeta:
  """
  ã‚«ãƒ¡ãƒ©ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹
  
  ãƒ•ãƒ¬ãƒ¼ãƒ IDã€ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãªã©ã®æƒ…å ±ã‚’æ ¼ç´ã—ã€
  ãƒ•ãƒ¬ãƒ¼ãƒ åŒæœŸã‚„ãƒ‰ãƒ­ãƒƒãƒ—ãƒ•ãƒ¬ãƒ¼ãƒ æ¤œå‡ºã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚
  """
  frame_id: int = 0          # ãƒ•ãƒ¬ãƒ¼ãƒ é€šç•ª
  timestamp_sof: int = 0     # ãƒ•ãƒ¬ãƒ¼ãƒ é–‹å§‹æ™‚åˆ»ï¼ˆnanosecondï¼‰
  timestamp_eof: int = 0     # ãƒ•ãƒ¬ãƒ¼ãƒ çµ‚äº†æ™‚åˆ»ï¼ˆnanosecondï¼‰

  def __init__(self, vipc=None):
    """
    VisionIpcClientã‹ã‚‰ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’åˆæœŸåŒ–
    
    Args:
      vipc: VisionIpcClient - ã‚«ãƒ¡ãƒ©ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆNoneã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ï¼‰
    """
    if vipc is not None:
      self.frame_id, self.timestamp_sof, self.timestamp_eof = vipc.frame_id, vipc.timestamp_sof, vipc.timestamp_eof

class E2EModelState:
  """
  E2Eï¼ˆEnd-to-Endï¼‰ãƒ¢ãƒ‡ãƒ«ã®çŠ¶æ…‹ã¨ãƒ‡ãƒ¼ã‚¿ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹
  
  ä¸»ãªæ©Ÿèƒ½:
  - å­¦ç¿’æ¸ˆã¿ONNXãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã¨åˆæœŸåŒ–
  - ã‚«ãƒ¡ãƒ©ãƒ•ãƒ¬ãƒ¼ãƒ ã€è»Šä¸¡çŠ¶æ…‹ã€ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±ã®ç®¡ç†
  - ãƒ¢ãƒ‡ãƒ«æ¨è«–ã®å®Ÿè¡Œã¨çµæœã®è§£æ
  - OpenPilotãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ³ã‚°å½¢å¼ã§ã®å‡ºåŠ›
  """
  # ã‚¯ãƒ©ã‚¹å±æ€§ã®å‹ãƒ’ãƒ³ãƒˆ
  frame: ModelFrame                     # ãƒ¡ã‚¤ãƒ³ã‚«ãƒ¡ãƒ©ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ç”¨
  wide_frame: ModelFrame               # ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ¡ãƒ©ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ç”¨  
  inputs: Dict[str, np.ndarray]        # ãƒ¢ãƒ‡ãƒ«å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒãƒ•ã‚¡
  output: np.ndarray                   # ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒãƒ•ã‚¡
  prev_desire: np.ndarray              # å‰å›ã®desireçŠ¶æ…‹ï¼ˆå¤‰åŒ–æ¤œå‡ºç”¨ï¼‰
  model: ModelRunner                   # ONNXãƒ¢ãƒ‡ãƒ«å®Ÿè¡Œã‚¨ãƒ³ã‚¸ãƒ³
  model_config: Dict[str, int]         # ãƒ¢ãƒ‡ãƒ«è¨­å®šï¼ˆå…¥åŠ›æ¬¡å…ƒãªã©ï¼‰

  def __init__(self, context: CLContext):
    """
    E2EModelStateã®åˆæœŸåŒ–
    
    Args:
      context: CLContext - OpenCLå®Ÿè¡Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆGPUå‡¦ç†ç”¨ï¼‰
    """
    # ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’èª­ã¿è¾¼ã¿ï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ï¼‰
    self.model_config = load_model_config()
    cloudlog.info(f"E2E Model initialized with config: {self.model_config}")
    
    # ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ç”¨ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®åˆæœŸåŒ–
    self.frame = ModelFrame(context)        # ãƒ¡ã‚¤ãƒ³ã‚«ãƒ¡ãƒ©ç”¨
    self.wide_frame = ModelFrame(context)   # ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ¡ãƒ©ç”¨
    
    # desireçŠ¶æ…‹è¿½è·¡ç”¨ï¼ˆå‰å›çŠ¶æ…‹ã¨ã®æ¯”è¼ƒã«ä½¿ç”¨ï¼‰
    self.prev_desire = np.zeros(ModelConstants.DESIRE_LEN, dtype=np.float32)
    
    # æ¨™æº–OpenPilotãƒ¢ãƒ‡ãƒ«ç”¨ã®å…¥åŠ›ãƒãƒƒãƒ•ã‚¡åˆæœŸåŒ–ï¼ˆäº’æ›æ€§ç¶­æŒã®ãŸã‚ï¼‰
    self.inputs = {
      'desire': np.zeros(ModelConstants.DESIRE_LEN * (ModelConstants.HISTORY_BUFFER_LEN+1), dtype=np.float32),
      'traffic_convention': np.zeros(ModelConstants.TRAFFIC_CONVENTION_LEN, dtype=np.float32),
      'lateral_control_params': np.zeros(ModelConstants.LATERAL_CONTROL_PARAMS_LEN, dtype=np.float32),
      'prev_desired_curv': np.zeros(ModelConstants.PREV_DESIRED_CURV_LEN * (ModelConstants.HISTORY_BUFFER_LEN+1), dtype=np.float32),
      'nav_features': np.zeros(ModelConstants.NAV_FEATURE_LEN, dtype=np.float32),
      'nav_instructions': np.zeros(ModelConstants.NAV_INSTRUCTION_LEN, dtype=np.float32),
      'features_buffer': np.zeros(ModelConstants.HISTORY_BUFFER_LEN * ModelConstants.FEATURE_LEN, dtype=np.float32),
    }

    # ===== ãƒ¢ãƒ‡ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆè¨­å®šã®åˆæœŸåŒ– =====
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèªï¼ˆãƒ¢ãƒ‡ãƒ«å‡ºåŠ›å½¢çŠ¶æƒ…å ±ã‚’å«ã‚€ï¼‰
    if METADATA_PATH.exists():
      # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å‡ºåŠ›ã‚µã‚¤ã‚ºã¨æ§‹é€ ã‚’èª­ã¿è¾¼ã¿
      with open(METADATA_PATH, 'rb') as f:
        model_metadata = pickle.load(f)
      self.output_slices = model_metadata['output_slices']  # å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²æ–¹æ³•
      net_output_size = model_metadata['output_shapes']['outputs'][1]  # å‡ºåŠ›ãƒ™ã‚¯ã‚¿ãƒ¼ã‚µã‚¤ã‚º
    else:
      cloudlog.warning("supercombo_metadata.pkl not found, using default values for custom E2E model")
      # ã‚«ã‚¹ã‚¿ãƒ ONNXãƒ¢ãƒ‡ãƒ«ç”¨ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
      self.output_slices = {}                                        # å‡ºåŠ›åˆ†å‰²ãªã—
      net_output_size = 2                                           # control_output: [aEgo, steeringTorque]

    # ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ãƒãƒƒãƒ•ã‚¡ã®åˆæœŸåŒ–
    self.output = np.zeros(net_output_size, dtype=np.float32)
    self.parser = Parser()  # å‡ºåŠ›ãƒ‘ãƒ¼ã‚µãƒ¼ï¼ˆæ¨™æº–OpenPilotãƒ¢ãƒ‡ãƒ«ç”¨ã€äº’æ›æ€§ç¶­æŒï¼‰

    # ===== E2E ONNXãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã¨åˆæœŸåŒ– =====
    cloudlog.warning(f"Loading E2E model from {MODEL_PATHS[ModelRunner.ONNX]}")
    
    # ã‚«ã‚¹ã‚¿ãƒ ONNXãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ãƒãƒƒãƒ•ã‚¡ã‚’è¨­å®šï¼ˆå›ºå®šã‚µã‚¤ã‚º: 2è¦ç´ ï¼‰
    custom_output_buffer = np.zeros(2, dtype=np.float32)  # [aEgo, steeringTorque]
    
    # ModelRunnerã®åˆæœŸåŒ–ï¼ˆGPUå®Ÿè¡Œã€ãƒ—ãƒªãƒ—ãƒ­ã‚»ã‚¹ç„¡åŠ¹ï¼‰
    self.model = ModelRunner(MODEL_PATHS, custom_output_buffer, Runtime.GPU, False, context)
    
    # ===== ã‚«ã‚¹ã‚¿ãƒ ONNXãƒ¢ãƒ‡ãƒ«ã®å…¥åŠ›å®šç¾© =====
    # å‹•çš„ãªæ¬¡å…ƒæ•°ã§ãƒ¢ãƒ‡ãƒ«å…¥åŠ›ã‚’è¨­å®šï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ï¼‰
    self.model.addInput("carState", None)        # [batch, car_state_dim] - è»Šä¸¡çŠ¶æ…‹ãƒ™ã‚¯ã‚¿ãƒ¼
    self.model.addInput("mainCamera", None)      # [batch, 3, image_size, image_size] - ãƒ¡ã‚¤ãƒ³ã‚«ãƒ¡ãƒ©ç”»åƒ
    self.model.addInput("zoomCamera", None)      # [batch, 3, image_size, image_size] - ã‚ºãƒ¼ãƒ ã‚«ãƒ¡ãƒ©ç”»åƒ
    self.model.addInput("navVector", None)       # [batch, nav_vector_dim] - ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ãƒ™ã‚¯ã‚¿ãƒ¼

  def slice_outputs(self, model_outputs: np.ndarray) -> Dict[str, np.ndarray]:
    """
    ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ã‚’è§£æã—ã¦è¾æ›¸å½¢å¼ã«å¤‰æ›
    
    ã‚«ã‚¹ã‚¿ãƒ E2Eãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›å½¢å¼:
    - model_outputs[0]: aEgo (åŠ é€Ÿåº¦æŒ‡ä»¤) [m/sÂ²]
    - model_outputs[1]: steeringTorque (ã‚¹ãƒ†ã‚¢ãƒªãƒ³ã‚°ãƒˆãƒ«ã‚¯æŒ‡ä»¤) [Nm]
    
    Args:
      model_outputs: np.ndarray - ãƒ¢ãƒ‡ãƒ«ã®ç”Ÿå‡ºåŠ› [2] 
      
    Returns:
      Dict[str, np.ndarray]: è§£ææ¸ˆã¿å‡ºåŠ›è¾æ›¸
        - 'control_output': åˆ¶å¾¡ä¿¡å· [1, 2]
        - 'raw_pred': ç”Ÿã®äºˆæ¸¬å€¤ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ã€SEND_RAW_PRED=1ã®å ´åˆï¼‰
    """
    # E2Eãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ã®è§£æ: [aEgo, steeringTorque]
    if len(model_outputs) >= 2:
      parsed_model_outputs = {
        'control_output': model_outputs.reshape(1, -1)  # ãƒãƒƒãƒå½¢å¼ã«å¤‰æ›: [1, 2]
      }
    else:
      # å‡ºåŠ›ã‚µã‚¤ã‚ºãŒä¸æ­£ãªå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
      cloudlog.warning(f"E2E model output size insufficient: {len(model_outputs)} < 2")
      parsed_model_outputs = {'outputs': model_outputs[np.newaxis, :]}
    
    # ãƒ‡ãƒãƒƒã‚°ç”¨: ç”Ÿã®äºˆæ¸¬å€¤ã‚‚å«ã‚ã‚‹ï¼ˆç’°å¢ƒå¤‰æ•°ã§åˆ¶å¾¡ï¼‰
    if SEND_RAW_PRED:
      parsed_model_outputs['raw_pred'] = model_outputs.copy()
      
    return parsed_model_outputs

  def run(self, buf: VisionBuf, wbuf: VisionBuf, transform: np.ndarray, transform_wide: np.ndarray,
                inputs: Dict[str, np.ndarray], prepare_only: bool) -> Optional[Dict[str, np.ndarray]]:
    """
    E2Eãƒ¢ãƒ‡ãƒ«ã®æ¨è«–å®Ÿè¡Œãƒ¡ã‚¤ãƒ³é–¢æ•°
    
    å‡¦ç†ãƒ•ãƒ­ãƒ¼:
    1. ã‚«ãƒ¡ãƒ©ç”»åƒã®å‰å‡¦ç†ï¼ˆYUVâ†’RGBã€ãƒªã‚µã‚¤ã‚ºã€æ­£è¦åŒ–ï¼‰
    2. è»Šä¸¡çŠ¶æ…‹ã®å‰å‡¦ç†ï¼ˆæ­£è¦åŒ–ã€æ¬¡å…ƒèª¿æ•´ï¼‰
    3. ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±ã®å‰å‡¦ç†
    4. ãƒ¢ãƒ‡ãƒ«æ¨è«–ã®å®Ÿè¡Œ
    5. çµæœã®è¿”å´
    
    Args:
      buf: VisionBuf - ãƒ¡ã‚¤ãƒ³ã‚«ãƒ¡ãƒ©ãƒ•ãƒ¬ãƒ¼ãƒ 
      wbuf: VisionBuf - ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ¡ãƒ©ãƒ•ãƒ¬ãƒ¼ãƒ   
      transform: np.ndarray - ãƒ¡ã‚¤ãƒ³ã‚«ãƒ¡ãƒ©å¤‰æ›è¡Œåˆ—
      transform_wide: np.ndarray - ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ¡ãƒ©å¤‰æ›è¡Œåˆ—
      inputs: Dict[str, np.ndarray] - ãã®ä»–ã®å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
      prepare_only: bool - æº–å‚™ã®ã¿ã§ãƒ¢ãƒ‡ãƒ«å®Ÿè¡Œã—ãªã„å ´åˆTrue
      
    Returns:
      Optional[Dict[str, np.ndarray]]: ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ï¼ˆprepare_only=Trueã®å ´åˆã¯Noneï¼‰
    """
    # ãƒ¢ãƒ‡ãƒ«è¨­å®šã‹ã‚‰å‹•çš„ã«ç”»åƒã‚µã‚¤ã‚ºã‚’å–å¾—
    image_size = self.model_config['image_size']
    
    # ===== Step 1: ã‚«ãƒ¡ãƒ©ç”»åƒã®å‰å‡¦ç† =====
    try:
      # ãƒ¡ã‚¤ãƒ³ã‚«ãƒ¡ãƒ©ã¨ã‚ºãƒ¼ãƒ ã‚«ãƒ¡ãƒ©ã®ç”»åƒã‚’å®Ÿéš›ã«å‡¦ç†ï¼ˆãƒ€ãƒŸãƒ¼ã§ã¯ãªãå®Ÿç”»åƒï¼‰
      main_camera_input = process_camera_frame(buf, transform)
      zoom_camera_input = process_camera_frame(wbuf, transform_wide)
      
      # å‰å‡¦ç†æ¸ˆã¿ç”»åƒã‚’ãƒ¢ãƒ‡ãƒ«å…¥åŠ›ãƒãƒƒãƒ•ã‚¡ã«è¨­å®š
      self.model.setInputBuffer("mainCamera", main_camera_input)
      self.model.setInputBuffer("zoomCamera", zoom_camera_input)
      
      cloudlog.debug(f"Camera inputs processed: main={main_camera_input.shape}, zoom={zoom_camera_input.shape}")
      
    except Exception as e:
      cloudlog.error(f"Error processing camera inputs: {e}")
      # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ã‚¼ãƒ­ã§åŸ‹ã‚ãŸãƒ€ãƒŸãƒ¼ç”»åƒã‚’ä½¿ç”¨ï¼ˆå‹•çš„ã‚µã‚¤ã‚ºå¯¾å¿œï¼‰
      dummy_image = np.zeros((1, 3, image_size, image_size), dtype=np.float32)
      self.model.setInputBuffer("mainCamera", dummy_image)
      self.model.setInputBuffer("zoomCamera", dummy_image)
    
    # ===== Step 2: è»Šä¸¡çŠ¶æ…‹ã®å‰å‡¦ç† =====
    try:
      # ãƒ¢ãƒ‡ãƒ«è¨­å®šã‹ã‚‰è»Šä¸¡çŠ¶æ…‹ãƒ™ã‚¯ã‚¿ãƒ¼ã®æ¬¡å…ƒæ•°ã‚’å–å¾—
      car_state_dim = self.model_config['car_state_dim']
      # è»Šä¸¡çŠ¶æ…‹ãƒ‡ãƒ¼ã‚¿ã‚’å‰å‡¦ç†ï¼ˆæ­£è¦åŒ–ã€æ¬¡å…ƒèª¿æ•´ï¼‰
      car_state_input = process_car_state(inputs.get('carState'), target_dim=car_state_dim)
      # å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ¢ãƒ‡ãƒ«å…¥åŠ›ãƒãƒƒãƒ•ã‚¡ã«è¨­å®š
      self.model.setInputBuffer("carState", car_state_input)
      cloudlog.debug(f"CarState input processed: shape={car_state_input.shape}, values={car_state_input[0][:min(4, car_state_dim)]}")
      
    except Exception as e:
      cloudlog.error(f"Error processing carState input: {e}")
      # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ã‚¼ãƒ­ãƒ™ã‚¯ã‚¿ãƒ¼ã‚’ä½¿ç”¨ï¼ˆå‹•çš„æ¬¡å…ƒå¯¾å¿œï¼‰
      car_state_dim = self.model_config['car_state_dim']
      car_state_input = np.zeros((1, car_state_dim), dtype=np.float32)
      self.model.setInputBuffer("carState", car_state_input)
    
    # ===== Step 3: ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±ã®å‰å‡¦ç† =====
    try:
      # ãƒ¢ãƒ‡ãƒ«è¨­å®šã‹ã‚‰ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ãƒ™ã‚¯ã‚¿ãƒ¼ã®æ¬¡å…ƒæ•°ã‚’å–å¾—
      nav_vector_dim = self.model_config['nav_vector_dim']
      # ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ç‰¹å¾´é‡ã‚’å‰å‡¦ç†ï¼ˆæ¬¡å…ƒèª¿æ•´ã€å€¤åŸŸåˆ¶é™ï¼‰
      nav_vector_input = process_nav_vector(inputs.get('nav_features'), target_dim=nav_vector_dim)
      # å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ¢ãƒ‡ãƒ«å…¥åŠ›ãƒãƒƒãƒ•ã‚¡ã«è¨­å®š
      self.model.setInputBuffer("navVector", nav_vector_input)
      cloudlog.debug(f"NavVector input processed: shape={nav_vector_input.shape}, nonzero={np.count_nonzero(nav_vector_input)}")
      
    except Exception as e:
      cloudlog.error(f"Error processing navVector input: {e}")
      # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ã‚¼ãƒ­ãƒ™ã‚¯ã‚¿ãƒ¼ã‚’ä½¿ç”¨ï¼ˆå‹•çš„æ¬¡å…ƒå¯¾å¿œï¼‰
      nav_vector_dim = self.model_config['nav_vector_dim']
      nav_vector_input = np.zeros((1, nav_vector_dim), dtype=np.float32)
      self.model.setInputBuffer("navVector", nav_vector_input)

    # ===== Step 4: æº–å‚™ã®ã¿ã®å ´åˆã¯æ—©æœŸãƒªã‚¿ãƒ¼ãƒ³ =====
    if prepare_only:
      # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‰ãƒ­ãƒƒãƒ—ç­‰ã§æ¨è«–ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹å ´åˆ
      return None

    # ===== Step 5: ãƒ¢ãƒ‡ãƒ«æ¨è«–ã®å®Ÿè¡Œ =====
    cloudlog.debug("E2E model executing with real inputs...")
    self.model.execute()  # GPUä¸Šã§ONNXãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè¡Œ
    
    # ===== Step 6: ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ã®å–å¾—ã¨è§£æ =====
    model_output = self.model.output  # ã‚«ã‚¹ã‚¿ãƒ å‡ºåŠ›ãƒãƒƒãƒ•ã‚¡ã‹ã‚‰çµæœã‚’å–å¾—
    outputs = self.slice_outputs(model_output)  # å‡ºåŠ›ã‚’è¾æ›¸å½¢å¼ã«å¤‰æ›
    return outputs
    

class DummyVisionBuf:
  """ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ç”¨ã®ãƒ€ãƒŸãƒ¼VisionBufã‚¯ãƒ©ã‚¹"""
  def __init__(self, height, width, frame_id=0):
    self.height = height
    self.width = width
    self.frame_id = frame_id
    # YUV420ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    yuv_height = height + height // 2  # Y + U/V planes
    self._yuv_data = np.random.randint(0, 255, (yuv_height, width), dtype=np.uint8)
    
    # VisionBufã¨åŒã˜dataå±æ€§ã‚’æä¾›
    self.data = self._yuv_data.tobytes()
    
  def get_yuv_420(self):
    """YUV420ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™"""
    return self._yuv_data


def generate_dummy_buffer(height, width, frame_id=0):
  """
  ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ç”¨ã®ãƒ€ãƒŸãƒ¼ã‚«ãƒ¡ãƒ©ãƒãƒƒãƒ•ã‚¡ã‚’ç”Ÿæˆ
  
  Args:
    height: ãƒ•ãƒ¬ãƒ¼ãƒ é«˜ã•
    width: ãƒ•ãƒ¬ãƒ¼ãƒ å¹…
    frame_id: ãƒ•ãƒ¬ãƒ¼ãƒ ID
    
  Returns:
    DummyVisionBuf: ãƒ€ãƒŸãƒ¼ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿
  """
  return DummyVisionBuf(height, width, frame_id)


class DummyFrameMeta:
  """ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ç”¨ã®ãƒ€ãƒŸãƒ¼FrameMetaã‚¯ãƒ©ã‚¹"""
  def __init__(self, frame_id=0, timestamp_sof=0):
    self.frame_id = frame_id
    self.timestamp_sof = timestamp_sof


def main(demo=False):
  """
  E2Eãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ¼ãƒ¢ãƒ³ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°
  
  å‡¦ç†ãƒ•ãƒ­ãƒ¼:
  1. ãƒ—ãƒ­ã‚»ã‚¹è¨­å®šã¨ãƒ­ã‚°åˆæœŸåŒ–
  2. OpenCLã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨E2Eãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
  3. ã‚«ãƒ¡ãƒ©ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®è¨­å®šã¨æ¥ç¶š
  4. ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ³ã‚°ï¼ˆPubMaster/SubMasterï¼‰ã®åˆæœŸåŒ–
  5. ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ã§ã®æ¨è«–å®Ÿè¡Œã¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡
  
  Args:
    demo: bool - ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ï¼ˆCarParamsã‚’è‡ªå‹•ç”Ÿæˆï¼‰
      - True: ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¢ãƒ¼ãƒ‰ï¼ˆget_demo_car_paramsä½¿ç”¨ï¼‰
      - False: å®Ÿæ©Ÿãƒ¢ãƒ¼ãƒ‰ï¼ˆå®Ÿéš›ã®CarParamsèª­ã¿è¾¼ã¿ï¼‰
  """
  cloudlog.warning("e2emodeld init")

  # ===== å®šæ•°å®šç¾©ï¼ˆã‚«ãƒ¡ãƒ©è§£åƒåº¦ï¼‰ =====
  H, W = 874, 1164  # OpenPilotæ¨™æº–ã‚«ãƒ¡ãƒ©è§£åƒåº¦

  # ===== ãƒ—ãƒ­ã‚»ã‚¹è¨­å®šã®åˆæœŸåŒ– =====
  sentry.set_tag("daemon", PROCESS_NAME)  # Sentryã‚¨ãƒ©ãƒ¼è¿½è·¡ç”¨ã‚¿ã‚°è¨­å®š
  cloudlog.bind(daemon=PROCESS_NAME)      # ãƒ­ã‚°ã«ãƒ—ãƒ­ã‚»ã‚¹åã‚’ãƒã‚¤ãƒ³ãƒ‰
  setproctitle(PROCESS_NAME)              # ãƒ—ãƒ­ã‚»ã‚¹åã‚’è¨­å®šï¼ˆpsã‚³ãƒãƒ³ãƒ‰ã§ç¢ºèªå¯èƒ½ï¼‰
  config_realtime_process(7, 54)          # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ—ãƒ­ã‚»ã‚¹è¨­å®šï¼ˆå„ªå…ˆåº¦7ã€CPU54ç•ªï¼‰

  # ===== å®Ÿè¡Œç’°å¢ƒã®åˆ¤å®šã¨é€šçŸ¥ =====
  if demo:
    cloudlog.warning("ğŸ® E2E Demo Mode: Using simulated car parameters")
  else:
    cloudlog.warning("ğŸš— E2E Real Mode: Using actual car parameters")

  # ===== OpenCLã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨E2Eãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ– =====
  try:
    cloudlog.warning("setting up CL context")
    cl_context = CLContext()  # OpenCLå®Ÿè¡Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆGPUå‡¦ç†ç”¨ï¼‰
    cloudlog.warning("CL context ready; loading E2E model")
    model = E2EModelState(cl_context)  # E2Eãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
    cloudlog.warning("E2E model loaded, e2emodeld starting")
  except Exception as e:
    cloudlog.error(f"Failed to initialize E2E model: {e}")
    import traceback
    cloudlog.error(f"E2E model initialization error traceback: {traceback.format_exc()}")
    raise

  # ===== ã‚«ãƒ¡ãƒ©ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®è¨­å®šï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ»å®Ÿæ©Ÿå¯¾å¿œï¼‰ =====
  try:
    cloudlog.warning("Setting up vision clients...")
    
    # ã‚«ãƒ¡ãƒ©ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®è‡ªå‹•æ¤œå‡ºï¼ˆç’°å¢ƒã«å¿œã˜ã¦é©å¿œï¼‰
    timeout_count = 0
    max_timeout = 50  # 5ç§’é–“ã®è©¦è¡Œ
    
    while True:
      available_streams = VisionIpcClient.available_streams("camerad", block=False)
      if available_streams:
        # ã‚¹ãƒˆãƒªãƒ¼ãƒ è¨­å®šã®åˆ¤å®š
        use_extra_client = (VisionStreamType.VISION_STREAM_WIDE_ROAD in available_streams and 
                           VisionStreamType.VISION_STREAM_ROAD in available_streams)
        main_wide_camera = VisionStreamType.VISION_STREAM_ROAD not in available_streams
        
        # æ¤œå‡ºã•ã‚ŒãŸã‚¹ãƒˆãƒªãƒ¼ãƒ æƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›ï¼ˆæ•´æ•°å€¤å¯¾å¿œï¼‰
        try:
          stream_names = [stream.name if hasattr(stream, 'name') else str(stream) for stream in available_streams]
        except:
          stream_names = [str(stream) for stream in available_streams]
        cloudlog.warning(f"ğŸ“¹ Detected camera streams: {stream_names}")
        break
        
      timeout_count += 1
      if timeout_count >= max_timeout:
        cloudlog.error("âš ï¸ Timeout waiting for camera streams")
        if demo:
          cloudlog.warning("ğŸ® Demo mode: Proceeding without camera streams (may use dummy data)")
          # ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ã§ã¯ç¶šè¡Œã‚’è¨±å¯
          available_streams = []
          use_extra_client = False
          main_wide_camera = True
          break
        else:
          raise RuntimeError("Camera streams not available in real mode")
      
      time.sleep(0.1)

    # ã‚«ãƒ¡ãƒ©ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
    if available_streams:
      vipc_client_main_stream = (VisionStreamType.VISION_STREAM_WIDE_ROAD if main_wide_camera 
                                else VisionStreamType.VISION_STREAM_ROAD)
      vipc_client_main = VisionIpcClient("camerad", vipc_client_main_stream, True, cl_context)
      vipc_client_extra = VisionIpcClient("camerad", VisionStreamType.VISION_STREAM_WIDE_ROAD, False, cl_context)
      
      cloudlog.warning(f"ğŸ“· Vision config: main_wide_camera={main_wide_camera}, use_extra_client={use_extra_client}")

      # ãƒ¡ã‚¤ãƒ³ã‚«ãƒ¡ãƒ©æ¥ç¶š
      connect_timeout = 0
      while not vipc_client_main.connect(False):
        connect_timeout += 1
        if connect_timeout > 100:  # 10ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
          if demo:
            cloudlog.warning("ğŸ® Demo mode: Main camera connection timeout, using dummy frames")
            break
          else:
            raise RuntimeError("Main camera connection failed")
        time.sleep(0.1)
      
      # è¿½åŠ ã‚«ãƒ¡ãƒ©æ¥ç¶šï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
      if use_extra_client:
        extra_timeout = 0
        while not vipc_client_extra.connect(False):
          extra_timeout += 1
          if extra_timeout > 100:  # 10ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
            cloudlog.warning("Extra camera connection timeout, proceeding with main camera only")
            use_extra_client = False
            break
          time.sleep(0.1)

      # æ¥ç¶šæˆåŠŸã®ç¢ºèª
      if vipc_client_main.connect(False):
        cloudlog.warning(f"âœ… Main camera connected: {vipc_client_main.buffer_len} buffers "
                        f"({vipc_client_main.width} x {vipc_client_main.height})")
      if use_extra_client and vipc_client_extra.connect(False):
        cloudlog.warning(f"âœ… Extra camera connected: {vipc_client_extra.buffer_len} buffers "
                        f"({vipc_client_extra.width} x {vipc_client_extra.height})")
    else:
      # ã‚«ãƒ¡ãƒ©ãªã—ãƒ¢ãƒ¼ãƒ‰ï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰
      cloudlog.warning("ğŸ® No camera mode: Using dummy camera clients")
      vipc_client_main = None
      vipc_client_extra = None
      use_extra_client = False
      main_wide_camera = True
      
  except Exception as e:
    cloudlog.error(f"Failed to setup vision clients: {e}")
    if demo:
      cloudlog.warning("ğŸ® Demo mode: Continuing despite vision setup failure")
      vipc_client_main = None
      vipc_client_extra = None
      use_extra_client = False
      main_wide_camera = True
    else:
      raise

  # messaging - E2Eãƒ¢ãƒ‡ãƒ«å°‚ç”¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒˆãƒ”ãƒƒã‚¯ï¼ˆe2eOutputã®ã¿ï¼‰
  try:
    pm = PubMaster(["e2eOutput"])
    sm = SubMaster(["carState", "navInstruction"])
  except Exception as e:
    cloudlog.error(f"Failed to setup messaging: {e}")
    raise
  
  # ãƒ‡ãƒãƒƒã‚°: åˆæœŸåŒ–å®Œäº†ã‚’ãƒ­ã‚°å‡ºåŠ›
  cloudlog.warning(f"E2E modeld initialized: frequency={E2E_MODEL_FREQ}Hz, messaging ready")

  params = Params()

  # setup filter to track dropped frames
  frame_dropped_filter = FirstOrderFilter(0., 10., 1. / ModelConstants.MODEL_FREQ)
  frame_id = 0
  last_vipc_frame_id = 0
  run_count = 0

  model_transform_main = np.zeros((3, 3), dtype=np.float32)
  model_transform_extra = np.zeros((3, 3), dtype=np.float32)
  live_calib_seen = False
  nav_features = np.zeros(ModelConstants.NAV_FEATURE_LEN, dtype=np.float32)
  nav_instructions = np.zeros(ModelConstants.NAV_INSTRUCTION_LEN, dtype=np.float32)
  buf_main, buf_extra = None, None
  meta_main = FrameMeta()
  meta_extra = FrameMeta()

  if demo:
    CP = get_demo_car_params()
  else:
    with car.CarParams.from_bytes(params.get("CarParams", block=True)) as msg:
      CP = msg
  cloudlog.info("e2emodeld got CarParams: %s", CP.carName)

  # TODO this needs more thought, use .2s extra for now to estimate other delays
  steer_delay = CP.steerActuatorDelay + .2

  DH = DesireHelper()

  cloudlog.warning("E2E model main loop starting")
  
  # E2Eå°‚ç”¨ã®æ›´æ–°é »åº¦åˆ¶å¾¡ã¨ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†
  last_e2e_update_time = 0.0
  e2e_update_interval = 1.0 / E2E_MODEL_FREQ  # 10Hzé–“éš”

  while True:
    current_time = time.monotonic()
    
    # E2Eæ›´æ–°é »åº¦åˆ¶å¾¡ï¼ˆè² è·åˆ†æ•£ã®ãŸã‚ï¼‰
    if current_time - last_e2e_update_time < e2e_update_interval:
      time.sleep(0.001)  # çŸ­æ™‚é–“ã‚¹ãƒªãƒ¼ãƒ—
      continue
    
    # ===== ã‚«ãƒ¡ãƒ©ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ»å®Ÿæ©Ÿå¯¾å¿œï¼‰ =====
    try:
      # ãƒ¡ã‚¤ãƒ³ã‚«ãƒ¡ãƒ©ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†
      if vipc_client_main is not None:
        # Keep receiving frames until we are at least 1 frame ahead of previous extra frame
        while meta_main.timestamp_sof < meta_extra.timestamp_sof + 25000000:
          buf_main = vipc_client_main.recv()
          meta_main = FrameMeta(vipc_client_main)
          if buf_main is None:
            break

        if buf_main is None:
          if demo:
            cloudlog.debug("ğŸ® Demo mode: No main frame, using dummy data")
            # ãƒ€ãƒŸãƒ¼ãƒ•ãƒ¬ãƒ¼ãƒ ãƒãƒƒãƒ•ã‚¡ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä½œæˆ
            buf_main = generate_dummy_buffer(H, W, frame_id)
            meta_main = DummyFrameMeta(frame_id, int(current_time * 1e9))
          else:
            cloudlog.error("vipc_client_main no frame")
            continue
      else:
        # ã‚«ãƒ¡ãƒ©ãªã—ãƒ¢ãƒ¼ãƒ‰ï¼ˆãƒ‡ãƒ¢å°‚ç”¨ï¼‰
        if demo:
          buf_main = generate_dummy_buffer(H, W, frame_id)
          meta_main = DummyFrameMeta(frame_id, int(current_time * 1e9))
        else:
          cloudlog.error("No main camera available in real mode")
          continue

      # è¿½åŠ ã‚«ãƒ¡ãƒ©ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†
      if use_extra_client and vipc_client_extra is not None:
        # Keep receiving extra frames until frame id matches main camera
        while True:
          buf_extra = vipc_client_extra.recv()
          meta_extra = FrameMeta(vipc_client_extra)
          if buf_extra is None or meta_main.timestamp_sof < meta_extra.timestamp_sof + 25000000:
            break

        if buf_extra is None:
          if demo:
            cloudlog.debug("ğŸ® Demo mode: No extra frame, using main frame")
            buf_extra = buf_main
            meta_extra = meta_main
          else:
            cloudlog.error("vipc_client_extra no frame")
            continue

        # ãƒ•ãƒ¬ãƒ¼ãƒ åŒæœŸãƒã‚§ãƒƒã‚¯
        if abs(meta_main.timestamp_sof - meta_extra.timestamp_sof) > 10000000:
          cloudlog.warning("frames out of sync! main: {} ({:.5f}), extra: {} ({:.5f})".format(
            meta_main.frame_id, meta_main.timestamp_sof / 1e9,
            meta_extra.frame_id, meta_extra.timestamp_sof / 1e9))
          if not demo:
            continue  # å®Ÿæ©Ÿã§ã¯åŒæœŸã‚¨ãƒ©ãƒ¼æ™‚ã¯ã‚¹ã‚­ãƒƒãƒ—
      else:
        # ã‚·ãƒ³ã‚°ãƒ«ã‚«ãƒ¡ãƒ©ãƒ¢ãƒ¼ãƒ‰
        buf_extra = buf_main
        meta_extra = meta_main

    except Exception as e:
      cloudlog.error(f"Camera frame processing error: {e}")
      if demo:
        cloudlog.warning("ğŸ® Demo mode: Continuing with dummy frames after error")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        buf_main = generate_dummy_buffer(H, W, frame_id)
        buf_extra = buf_main
        meta_main = DummyFrameMeta(frame_id, int(current_time * 1e9))
        meta_extra = meta_main
      else:
        continue

    sm.update(0)
    desire = DH.desire
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ï¼ˆå…ƒã®SubMasterã‹ã‚‰å‰Šé™¤ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ï¼‰
    is_rhd = True  # å³ãƒãƒ³ãƒ‰ãƒ«è»Šã¨ã—ã¦è¨­å®š
    frame_id = meta_main.frame_id  # ãƒ¡ã‚¤ãƒ³ã‚«ãƒ¡ãƒ©ã®ãƒ•ãƒ¬ãƒ¼ãƒ IDã‚’ä½¿ç”¨
    lateral_control_params = np.array([sm["carState"].vEgo, steer_delay], dtype=np.float32)
    
    # ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ãŒãªã„ãŸã‚ã€å˜ä½è¡Œåˆ—ã‚’ä½¿ç”¨
    if not live_calib_seen:
      model_transform_main = np.eye(3, dtype=np.float32)
      model_transform_extra = np.eye(3, dtype=np.float32)
      live_calib_seen = True

    traffic_convention = np.zeros(2)
    traffic_convention[int(is_rhd)] = 1

    vec_desire = np.zeros(ModelConstants.DESIRE_LEN, dtype=np.float32)
    if desire >= 0 and desire < ModelConstants.DESIRE_LEN:
      vec_desire[desire] = 1

    # Enable/disable nav features - navInstructionã®ã¿ä½¿ç”¨
    timestamp_llk = 0  # navModelã‚’ä½¿ç”¨ã—ã¦ã„ãªã„ãŸã‚0ã«è¨­å®š
    nav_valid = sm.valid["navInstruction"]  # navInstructionã®æœ‰åŠ¹æ€§ã‚’ãƒã‚§ãƒƒã‚¯
    nav_enabled = nav_valid  # ExperimentalModeãƒã‚§ãƒƒã‚¯ã‚’ç°¡ç•¥åŒ–

    if not nav_enabled:
      nav_features[:] = 0
      nav_instructions[:] = 0

    # navModelã‚’ä½¿ç”¨ã—ãªã„ãŸã‚ã€nav_featuresã¯å¸¸ã«0
    nav_features[:] = 0

    if nav_enabled and sm.updated["navInstruction"]:
      nav_instructions[:] = 0
      for maneuver in sm["navInstruction"].allManeuvers:
        distance_idx = 25 + int(maneuver.distance / 20)
        direction_idx = 0
        if maneuver.modifier in ("left", "slight left", "sharp left"):
          direction_idx = 1
        if maneuver.modifier in ("right", "slight right", "sharp right"):
          direction_idx = 2
        if 0 <= distance_idx < 50:
          nav_instructions[distance_idx*3 + direction_idx] = 1

    # tracked dropped frames
    vipc_dropped_frames = max(0, meta_main.frame_id - last_vipc_frame_id - 1)
    frames_dropped = frame_dropped_filter.update(min(vipc_dropped_frames, 10))
    if run_count < 10: # let frame drops warm up
      frame_dropped_filter.x = 0.
      frames_dropped = 0.
    run_count = run_count + 1

    frame_drop_ratio = frames_dropped / (1 + frames_dropped)
    prepare_only = vipc_dropped_frames > 0
    if prepare_only:
      cloudlog.error(f"skipping E2E model eval. Dropped {vipc_dropped_frames} frames")

    inputs: Dict[str, np.ndarray] = {
      'desire': vec_desire,
      'traffic_convention': traffic_convention,
      'lateral_control_params': lateral_control_params,
      'nav_features': nav_features,
      'nav_instructions': nav_instructions}

    # ãƒ‡ãƒãƒƒã‚°: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬çµ±è¨ˆã‚’å‡ºåŠ›ï¼ˆæ¨è«–ãŒå®Ÿè¡Œã•ã‚Œã‚‹å ´åˆã®ã¿ï¼‰
    if not prepare_only:
      cloudlog.debug(f"E2E inputs - desire: {vec_desire[:3]}, nav_feat_mean: {np.mean(nav_features):.6f}, nav_inst_sum: {np.sum(nav_instructions)}")

    mt1 = time.perf_counter()
    model_output = model.run(buf_main, buf_extra, model_transform_main, model_transform_extra, inputs, prepare_only)
    mt2 = time.perf_counter()
    model_execution_time = mt2 - mt1

    if model_output is not None:
      cloudlog.debug(f"E2E model execution time: {model_execution_time:.4f}s")
      
      try:
        # E2Eãƒ¢ãƒ‡ãƒ«ï¼ˆcheckpoint_epoch_19_best.onnxï¼‰ã®å®Ÿéš›ã®å‡ºåŠ›ã‚’å–å¾—
        # ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›: control_output [batch_size, 2] - [aEgo, steeringTorque]
        e2e_aEgo = 0.0
        e2e_steeringTorque = 0.0
        
        # ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ã® 'control_output' ã‚­ãƒ¼ã‚’ç¢ºèª
        if 'control_output' in model_output:
          control_outputs = model_output['control_output']
          cloudlog.debug(f"E2E ONNX control_output shape: {control_outputs.shape}")
          
          # control_outputã‹ã‚‰å€¤ã‚’å–å¾— [1, 2] -> [aEgo, steeringTorque]
          if hasattr(control_outputs, 'flatten') and len(control_outputs.flatten()) >= 2:
            flat_outputs = control_outputs.flatten()
            e2e_aEgo = float(flat_outputs[0])
            e2e_steeringTorque = float(flat_outputs[1])
            cloudlog.debug(f"E2E parsed from control_output: aEgo={e2e_aEgo:.6f}, steeringTorque={e2e_steeringTorque:.6f}")
          else:
            cloudlog.warning(f"E2E model control_output format unexpected: {control_outputs.shape}")
            
        # ONNXãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã‚’å‡¦ç†ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        elif 'raw_pred' in model_output:
          raw_prediction = model_output['raw_pred']
          cloudlog.debug(f"E2E ONNX raw prediction shape: {raw_prediction.shape}")
          
          # ONNXãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã¯ [batch_size, 2] = [aEgo, steeringTorque]
          if len(raw_prediction) >= 2:
            e2e_aEgo = float(raw_prediction[0])           # ç¬¬1è¦ç´ : åŠ é€Ÿåº¦æŒ‡ä»¤
            e2e_steeringTorque = float(raw_prediction[1]) # ç¬¬2è¦ç´ : ã‚¹ãƒ†ã‚¢ãƒªãƒ³ã‚°ãƒˆãƒ«ã‚¯æŒ‡ä»¤
          else:
            cloudlog.warning(f"E2E model output insufficient: {len(raw_prediction)} < 2")
            
        # ãƒ‘ãƒ¼ã‚¹ã•ã‚ŒãŸå‡ºåŠ›ãŒã‚ã‚‹å ´åˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        elif 'outputs' in model_output:
          outputs = model_output['outputs']
          cloudlog.debug(f"E2E ONNX parsed outputs shape: {outputs.shape}")
          
          # control_outputã‹ã‚‰å€¤ã‚’å–å¾—
          if hasattr(outputs, 'flatten') and len(outputs.flatten()) >= 2:
            flat_outputs = outputs.flatten()
            e2e_aEgo = float(flat_outputs[0])
            e2e_steeringTorque = float(flat_outputs[1])
          else:
            cloudlog.warning("E2E model parsed output format unexpected")
            
        else:
          cloudlog.warning(f"E2E model output format not recognized. Available keys: {list(model_output.keys())}")
        
        # E2Eå°‚ç”¨ã®å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        # ONNXãƒ¢ãƒ‡ãƒ« checkpoint_epoch_19_best.onnx ã® control_output [2] ã«å¯¾å¿œ
        e2e_output_data = {
          'aEgo': e2e_aEgo,                    # åŠ é€Ÿåº¦æŒ‡ä»¤ (m/sÂ²)
          'steeringTorque': e2e_steeringTorque, # ã‚¹ãƒ†ã‚¢ãƒªãƒ³ã‚°ãƒˆãƒ«ã‚¯æŒ‡ä»¤ (Nm)
        }
        
        cloudlog.debug(f"E2E ONNX model predictions - aEgo: {e2e_aEgo:.6f} m/sÂ², steeringTorque: {e2e_steeringTorque:.6f} Nm, execTime: {model_execution_time:.3f}ms")
        
        # E2Eå°‚ç”¨ã®å‡ºåŠ›ã‚’ãƒ­ã‚°ã«è¨˜éŒ²
        cloudlog.warning(f"E2E OUTPUT: aEgo={e2e_aEgo:.4f}, steeringTorque={e2e_steeringTorque:.4f}")
        
        # rlogã«è¨˜éŒ²ã™ã‚‹ãŸã‚ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ï¼ˆe2eOutputã®ã¿ï¼‰
        if pm is not None:
          import cereal.messaging as messaging
          
          # e2eOutputãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆãƒŸãƒ‹ãƒãƒ«æ§‹é€ ï¼‰
          e2e_out_msg = messaging.new_message('e2eOutput')
          e2e_out_msg.e2eOutput.aEgo = e2e_aEgo
          e2e_out_msg.e2eOutput.steeringTorque = e2e_steeringTorque
          e2e_out_msg.e2eOutput.timestamp = int(time.time_ns())
          e2e_out_msg.e2eOutput.isValid = True
          
          # é‡è¦: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ¬ãƒ™ãƒ«ã®validãƒ•ãƒ©ã‚°ã‚‚è¨­å®š
          e2e_out_msg.valid = True
          
          pm.send('e2eOutput', e2e_out_msg)
          
          # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ç¢ºèª
          cloudlog.debug(f"E2E message sent: aEgo={e2e_aEgo:.4f}, steeringTorque={e2e_steeringTorque:.4f}, isValid=True")
        
        # E2Eæ›´æ–°æ™‚é–“ã‚’è¨˜éŒ²ï¼ˆè² è·åˆ†æ•£åˆ¶å¾¡ç”¨ï¼‰
        last_e2e_update_time = current_time
        
      except Exception as e:
        cloudlog.error(f"Error processing E2E model output: {e}")
        import traceback
        cloudlog.error(f"E2E error traceback: {traceback.format_exc()}")
        
        # ã‚¨ãƒ©ãƒ¼æ™‚ã§ã‚‚ç„¡åŠ¹ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        try:
          e2e_out_msg = messaging.new_message('e2eOutput')
          e2e_out_msg.e2eOutput.aEgo = 0.0
          e2e_out_msg.e2eOutput.steeringTorque = 0.0
          e2e_out_msg.e2eOutput.timestamp = int(time.time_ns())
          e2e_out_msg.e2eOutput.isValid = False
          
          # ã‚¨ãƒ©ãƒ¼æ™‚: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ¬ãƒ™ãƒ«ã®validã‚‚ç„¡åŠ¹ã«è¨­å®š
          e2e_out_msg.valid = False
          
          pm.send('e2eOutput', e2e_out_msg)
          cloudlog.debug("E2E error: sent invalid message")
        except Exception as msg_error:
          cloudlog.error(f"Failed to send error message: {msg_error}")

    # ãƒ•ãƒ¬ãƒ¼ãƒ IDã®æ›´æ–°ï¼ˆæ¬¡å›ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‰ãƒ­ãƒƒãƒ—æ¤œå‡ºç”¨ï¼‰
    last_vipc_frame_id = meta_main.frame_id


# ===== ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œéƒ¨ =====
if __name__ == "__main__":
  """
  E2Eãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ¼ãƒ¢ãƒ³ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
  
  ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°:
    --demo: ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ï¼ˆCarParamsã‚’è‡ªå‹•ç”Ÿæˆã€å®Ÿè»Šãªã—ã§ãƒ†ã‚¹ãƒˆå¯èƒ½ï¼‰
  
  å®Ÿè¡Œä¾‹:
    python selfdrive/modeld/e2emodeld.py          # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰
    python selfdrive/modeld/e2emodeld.py --demo   # ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰
  """
  try:
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®è§£æ
    import argparse
    parser = argparse.ArgumentParser(description='E2Eè‡ªå‹•é‹è»¢ãƒ¢ãƒ‡ãƒ«å®Ÿè¡Œãƒ‡ãƒ¼ãƒ¢ãƒ³')
    parser.add_argument('--demo', action='store_true', 
                       help='ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ï¼ˆCarParamsè‡ªå‹•ç”Ÿæˆã€å®Ÿè»Šæ¥ç¶šä¸è¦ï¼‰')
    args = parser.parse_args()
    
    # ãƒ¡ã‚¤ãƒ³é–¢æ•°ã®å®Ÿè¡Œ
    main(demo=args.demo)
    
  except KeyboardInterrupt:
    # Ctrl+Cã«ã‚ˆã‚‹æ­£å¸¸çµ‚äº†
    cloudlog.warning(f"child {PROCESS_NAME} got SIGINT")
  except Exception:
    # äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ã®å ´åˆã€Sentryã«é€ä¿¡ã—ã¦å†ç™ºç”Ÿ
    sentry.capture_exception()
    raise