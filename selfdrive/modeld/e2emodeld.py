#!/usr/bin/env python3
"""
E2E (End-to-End) ï¿½ï¿½ï¿½ï¿½ï¿½^ï¿½]ï¿½ï¿½ï¿½fï¿½ï¿½ï¿½ï¿½ï¿½sï¿½fï¿½[ï¿½ï¿½ï¿½ï¿½
"""

import os
import time
import numpy as np
import cv2
from cereal import car
from pathlib import Path
from typing import Dict, Optional
from setproctitle import setproctitle
from cereal.messaging import PubMaster, SubMaster
from cereal.visionipc import VisionIpcClient, VisionStreamType, VisionBuf
import onnxruntime as ort
from openpilot.common.swaglog import cloudlog
from openpilot.common.params import Params
from openpilot.common.filter_simple import FirstOrderFilter
from openpilot.common.realtime import config_realtime_process
from openpilot.selfdrive import sentry
from openpilot.selfdrive.car.car_helpers import get_demo_car_params
from openpilot.selfdrive.controls.lib.desire_helper import DesireHelper
from openpilot.selfdrive.modeld.runners import ModelRunner
from openpilot.selfdrive.modeld.constants import ModelConstants
from openpilot.selfdrive.modeld.models.commonmodel_pyx import ModelFrame, CLContext
from collections import deque

# ===== ï¿½vï¿½ï¿½ï¿½Zï¿½Xï¿½İ’ï¿½ =====
PROCESS_NAME = "selfdrive.modeld.e2emodeld"
SEND_RAW_PRED = os.getenv("SEND_RAW_PRED")  # ï¿½fï¿½oï¿½bï¿½Oï¿½p: ï¿½ï¿½ï¿½Ì—\ï¿½ï¿½ï¿½lï¿½ï¿½ï¿½Mï¿½tï¿½ï¿½ï¿½O
SEND_E2E_OUTPUT = os.getenv(
    "SEND_E2E_OUTPUT", "1"
)  # E2Eï¿½oï¿½Í‚ï¿½ï¿½ï¿½É‘ï¿½ï¿½Mï¿½iï¿½fï¿½tï¿½Hï¿½ï¿½ï¿½gï¿½Lï¿½ï¿½ï¿½j

# ===== ï¿½ï¿½ï¿½fï¿½ï¿½ï¿½tï¿½@ï¿½Cï¿½ï¿½ï¿½pï¿½Xï¿½İ’ï¿½ =====
# ï¿½Jï¿½Xï¿½^ï¿½ï¿½ï¿½wï¿½Kï¿½Ï‚ï¿½E2Eï¿½ï¿½ï¿½fï¿½ï¿½ï¿½Ìƒpï¿½Xï¿½İ’ï¿½
MODEL_PATHS = {
    ModelRunner.ONNX: Path(__file__).parent
    # / "models/e2e_model.onnx"  # ï¿½Wï¿½ï¿½ONNXï¿½Åiï¿½tï¿½Hï¿½[ï¿½ï¿½ï¿½oï¿½bï¿½Nï¿½j
    # / "models/checkpoint_epoch_57_best.onnx"  # v2.1 Transformer
    / "models/checkpoint_epoch_90_best.onnx"  # v2.1 LSTM

}

E2E_MODEL_FREQ = 10.0  # 10Hz
IMAGE_SIZE = 224

# ï¿½Vï¿½ï¿½ï¿½ï¿½carStateï¿½Ìï¿½ï¿½ï¿½ï¿½ï¿½ï¿½`
CAR_STATE_DIM = 5
PREDICTION_HORIZON = 10

car_state_queue: deque = deque(maxlen=120)


def update_car_state_queue(car_state_data):
    timestamp = time.time()
    car_state_entry = {
        "timestamp": timestamp,
        "vEgo": car_state_data.get("vEgo", 0.0),
        "aEgo": car_state_data.get("aEgo", 0.0),
        "steeringAngleDeg": car_state_data.get("steeringAngleDeg", 0.0),
        "leftBlinker": car_state_data.get("leftBlinker", False),
        "rightBlinker": car_state_data.get("rightBlinker", False),
    }
    car_state_queue.append(car_state_entry)


def get_past_car_state_data(queue, step=0.5, steps=10):
    current_time = time.time()
    past_data = {
        "vEgos": [],
        "aEgos": [],
        "steeringAngleDegs": [],
        "leftBlinkers": [],
        "rightBlinkers": [],
    }

    for i in range(steps):
        target_time = current_time - (i * step)
        closest_entry = min(queue, key=lambda x: abs(x["timestamp"] - target_time))
        past_data["vEgos"].append(closest_entry["vEgo"])
        past_data["aEgos"].append(closest_entry["aEgo"])
        past_data["steeringAngleDegs"].append(closest_entry["steeringAngleDeg"])
        past_data["leftBlinkers"].append(1 if closest_entry["leftBlinker"] else 0)
        past_data["rightBlinkers"].append(1 if closest_entry["rightBlinker"] else 0)

    return past_data


def process_camera_frame(buf: VisionBuf) -> np.ndarray:
    """
    VisionBufï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Û‚Ì‰æ‘œï¿½fï¿½[ï¿½^ï¿½ï¿½ï¿½æ“¾ï¿½ï¿½ï¿½AE2Eï¿½ï¿½ï¿½fï¿½ï¿½ï¿½pï¿½É‘Oï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½s
    """
    try:
        # VisionBufï¿½Ì—Lï¿½ï¿½ï¿½ï¿½ï¿½`ï¿½Fï¿½bï¿½N
        if buf is None:
            cloudlog.warning("VisionBuf is None, using dummy image")
            return np.zeros((3, IMAGE_SIZE, IMAGE_SIZE), dtype=np.float32)

        # YUV420: Y(ï¿½Pï¿½x) + U/V(ï¿½Fï¿½ï¿½)ï¿½ï¿½ï¿½cï¿½ï¿½ï¿½ï¿½ï¿½ï¿½1.5ï¿½{ï¿½ÌƒTï¿½Cï¿½Yï¿½ÅŠiï¿½[
        print("buf.width =", buf.width)
        print("buf.height =", buf.height)
        print("len(buf.data) =", len(buf.data))
        yuv_img = np.frombuffer(buf.data, dtype=np.uint8).reshape(
            (buf.height + buf.height // 2, buf.width)
        )

        # YUV420ï¿½ï¿½RGBï¿½É•ÏŠï¿½
        rgb_img = cv2.cvtColor(yuv_img, cv2.COLOR_YUV2RGB_I420)

        # ï¿½æ‘œï¿½Ìƒï¿½ï¿½Tï¿½Cï¿½Y (ï¿½ï¿½ï¿½ğ‘œ“x ï¿½ï¿½ 224x224)
        resized_img = cv2.resize(
            rgb_img, (IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_LINEAR
        )

        # [0, 255] ï¿½ï¿½ [0, 1] ï¿½ï¿½ï¿½Kï¿½ï¿½
        normalized_img = resized_img.astype(np.float32) / 255.0

        # HWC ï¿½ï¿½ CHW (Height, Width, Channel ï¿½ï¿½ Channel, Height, Width)
        # PyTorchï¿½ï¿½ï¿½fï¿½ï¿½ï¿½Ì“ï¿½ï¿½ÍŒ`ï¿½ï¿½ï¿½É•ÏŠï¿½
        transposed_img = normalized_img.transpose(2, 0, 1)

        return transposed_img

    except Exception as e:
        cloudlog.error(f"Error processing camera frame: {e}")
        # ï¿½Gï¿½ï¿½ï¿½[ï¿½ï¿½ï¿½Íƒ[ï¿½ï¿½ï¿½Å–ï¿½ï¿½ß‚ï¿½ï¿½_ï¿½~ï¿½[ï¿½æ‘œï¿½ï¿½Ô‚ï¿½
        return np.zeros((3, IMAGE_SIZE, IMAGE_SIZE), dtype=np.float32)


class FrameMeta:
    """
    ï¿½Jï¿½ï¿½ï¿½ï¿½ï¿½tï¿½ï¿½ï¿½[ï¿½ï¿½ï¿½Ìƒï¿½ï¿½^ï¿½fï¿½[ï¿½^ï¿½ï¿½ï¿½Ç—ï¿½ï¿½ï¿½ï¿½ï¿½Nï¿½ï¿½ï¿½X

    ï¿½tï¿½ï¿½ï¿½[ï¿½ï¿½IDï¿½Aï¿½^ï¿½Cï¿½ï¿½ï¿½Xï¿½^ï¿½ï¿½ï¿½vï¿½È‚Ç‚Ìï¿½ï¿½ï¿½ï¿½iï¿½[ï¿½ï¿½ï¿½A
    ï¿½tï¿½ï¿½ï¿½[ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½hï¿½ï¿½ï¿½bï¿½vï¿½tï¿½ï¿½ï¿½[ï¿½ï¿½ï¿½ï¿½ï¿½oï¿½Égï¿½pï¿½ï¿½ï¿½ï¿½Ü‚ï¿½ï¿½B
    """

    frame_id: int = 0  # ï¿½tï¿½ï¿½ï¿½[ï¿½ï¿½ï¿½Ê”ï¿½
    timestamp_sof: int = 0  # ï¿½tï¿½ï¿½ï¿½[ï¿½ï¿½ï¿½Jï¿½nï¿½ï¿½ï¿½ï¿½ï¿½inanosecondï¿½j
    timestamp_eof: int = 0  # ï¿½tï¿½ï¿½ï¿½[ï¿½ï¿½ï¿½Iï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½inanosecondï¿½j

    def __init__(self, vipc=None):
        """
        VisionIpcClientï¿½ï¿½ï¿½ï¿½ ï¿½ï¿½ï¿½^ï¿½fï¿½[ï¿½^ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½

        Args:
          vipc: VisionIpcClient - ï¿½Jï¿½ï¿½ï¿½ï¿½ï¿½Nï¿½ï¿½ï¿½Cï¿½Aï¿½ï¿½ï¿½gï¿½iNoneï¿½Ìê‡ï¿½Íƒfï¿½tï¿½Hï¿½ï¿½ï¿½gï¿½lï¿½ï¿½ï¿½gï¿½pï¿½j
        """
        if vipc is not None:
            self.frame_id, self.timestamp_sof, self.timestamp_eof = (
                vipc.frame_id,
                vipc.timestamp_sof,
                vipc.timestamp_eof,
            )


class E2EModelState:
    """
    E2Eï¿½iEnd-to-Endï¿½jï¿½ï¿½ï¿½fï¿½ï¿½ï¿½Ìï¿½Ô‚Æƒfï¿½[ï¿½^ï¿½ï¿½ï¿½Ç—ï¿½ï¿½ï¿½ï¿½ï¿½Nï¿½ï¿½ï¿½X
    """

    # ï¿½Nï¿½ï¿½ï¿½Xï¿½ï¿½ï¿½ï¿½ï¿½ÌŒ^ï¿½qï¿½ï¿½ï¿½g
    frame: ModelFrame  # ï¿½ï¿½ï¿½Cï¿½ï¿½ï¿½Jï¿½ï¿½ï¿½ï¿½ï¿½tï¿½ï¿½ï¿½[ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½p
    wide_frame: ModelFrame  # ï¿½ï¿½ï¿½Cï¿½hï¿½Jï¿½ï¿½ï¿½ï¿½ï¿½tï¿½ï¿½ï¿½[ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½p
    session: ort.InferenceSession  # ONNXï¿½ï¿½ï¿½ï¿½ï¿½^ï¿½Cï¿½ï¿½ï¿½Zï¿½bï¿½Vï¿½ï¿½ï¿½ï¿½
    inputs: Dict[str, np.ndarray]  # ï¿½ï¿½ï¿½fï¿½ï¿½ï¿½ï¿½ï¿½Íƒfï¿½[ï¿½^
    output: Dict[str, float]  # ï¿½ï¿½ï¿½fï¿½ï¿½ï¿½oï¿½Íƒfï¿½[ï¿½^

    def __init__(self, context: CLContext):
        """
        E2EModelStateï¿½Ìï¿½ï¿½ï¿½ï¿½ï¿½
        """
        # ï¿½tï¿½ï¿½ï¿½[ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½pï¿½Iï¿½uï¿½Wï¿½Fï¿½Nï¿½gï¿½Ìï¿½ï¿½ï¿½ï¿½ï¿½
        self.frame = ModelFrame(context)  # ï¿½ï¿½ï¿½Cï¿½ï¿½ï¿½Jï¿½ï¿½ï¿½ï¿½ï¿½p
        self.wide_frame = ModelFrame(context)  # ï¿½ï¿½ï¿½Cï¿½hï¿½Jï¿½ï¿½ï¿½ï¿½ï¿½p

        self.session = ort.InferenceSession(
            MODEL_PATHS[ModelRunner.ONNX].as_posix(), providers=["CPUExecutionProvider"]
        )

        self.inputs = {
            "mainCamera": np.zeros((1, 3, 224, 224), dtype=np.float32),
            "zoomCamera": np.zeros((1, 3, 224, 224), dtype=np.float32),
            "navVector": np.zeros((1, 150), dtype=np.float32),
            "carState": np.zeros((1, CAR_STATE_DIM, PREDICTION_HORIZON), dtype=np.float32),  # ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ê‚½carState
        }

        self.output = {
            "pred_vEgo": float(0.0),
            "pred_aEgo": float(0.0),
            "pred_steeringAngleDeg": float(0.0),
        }

    def run(
        self, buf: VisionBuf, wbuf: VisionBuf, inputs: Dict[str, np.ndarray]
    ) -> Optional[Dict[str, float]]:
        """
        E2Eï¿½ï¿½ï¿½fï¿½ï¿½ï¿½Ìï¿½ï¿½_ï¿½ï¿½ï¿½sï¿½ï¿½ï¿½Cï¿½ï¿½ï¿½Öï¿½
        """

        try:
            main_camera_input = process_camera_frame(buf)
            zoom_camera_input = process_camera_frame(wbuf)
            self.inputs["mainCamera"] = np.expand_dims(main_camera_input, axis=0)
            self.inputs["zoomCamera"] = np.expand_dims(zoom_camera_input, axis=0)
        except Exception as e:
            cloudlog.error(f"Error processing camera inputs: {e}")

        try:
            # ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ê‚½carStateï¿½ï¿½ï¿½ì¬
            past_car_state_data = get_past_car_state_data(car_state_queue, step=0.5, steps=PREDICTION_HORIZON)
            car_state_tensor = np.stack([
                np.array(past_car_state_data["vEgos"], dtype=np.float32) / 10,  # ï¿½Xï¿½Pï¿½[ï¿½ï¿½ï¿½ï¿½ï¿½O
                np.array(past_car_state_data["aEgos"], dtype=np.float32),
                np.array(past_car_state_data["steeringAngleDegs"], dtype=np.float32) / 100,  # ï¿½Xï¿½Pï¿½[ï¿½ï¿½ï¿½ï¿½ï¿½O
                np.array(past_car_state_data["leftBlinkers"], dtype=np.float32),
                np.array(past_car_state_data["rightBlinkers"], dtype=np.float32),
            ], axis=0)  # (CAR_STATE_DIM, PREDICTION_HORIZON)

            self.inputs["carState"] = np.expand_dims(car_state_tensor, axis=0)  # (1, CAR_STATE_DIM, PREDICTION_HORIZON)
        except Exception as e:
            cloudlog.error(f"Error processing carState input: {e}")

        try:
            self.inputs["navVector"] = np.expand_dims(inputs.get(
                "navVector", np.zeros(150, dtype=np.float32)
            ), axis=0)
        except Exception as e:
            cloudlog.error(f"Error processing navVector input: {e}")

        pred_vEgos, pred_aEgos, pred_steeringAngleDegs = self.session.run(None, self.inputs)
        self.output["pred_vEgo"] = float(pred_vEgos[0][0] * 10.0)  # m/sï¿½ÉƒXï¿½Pï¿½[ï¿½ï¿½ï¿½ï¿½ï¿½O
        self.output["pred_aEgo"] = float(pred_aEgos[0][0])
        self.output["pred_steeringAngleDeg"] = float(pred_steeringAngleDegs[0][0] * 100.0)  # degï¿½ÉƒXï¿½Pï¿½[ï¿½ï¿½ï¿½ï¿½ï¿½O
        return self.output


def main(demo=False):
    """
    E2Eï¿½ï¿½ï¿½fï¿½ï¿½ï¿½fï¿½[ï¿½ï¿½ï¿½ï¿½ï¿½Ìƒï¿½ï¿½Cï¿½ï¿½ï¿½Öï¿½
    """
    cloudlog.warning("e2emodeld init")

    # ===== ï¿½vï¿½ï¿½ï¿½Zï¿½Xï¿½İ’ï¿½Ìï¿½ï¿½ï¿½ï¿½ï¿½ =====
    sentry.set_tag("daemon", PROCESS_NAME)  # Sentryï¿½Gï¿½ï¿½ï¿½[ï¿½ÇÕ—pï¿½^ï¿½Oï¿½İ’ï¿½
    cloudlog.bind(daemon=PROCESS_NAME)  # ï¿½ï¿½ï¿½Oï¿½Éƒvï¿½ï¿½ï¿½Zï¿½Xï¿½ï¿½ï¿½ï¿½ï¿½oï¿½Cï¿½ï¿½ï¿½h
    setproctitle(PROCESS_NAME)  # ï¿½vï¿½ï¿½ï¿½Zï¿½Xï¿½ï¿½ï¿½ï¿½İ’ï¿½ipsï¿½Rï¿½}ï¿½ï¿½ï¿½hï¿½ÅŠmï¿½Fï¿½Â”\ï¿½j
    config_realtime_process(6, 53)  # ï¿½ï¿½ï¿½Aï¿½ï¿½ï¿½^ï¿½Cï¿½ï¿½ï¿½vï¿½ï¿½ï¿½Zï¿½Xï¿½İ’ï¿½iï¿½Dï¿½ï¿½x7ï¿½ACPU54ï¿½Ôj

    # ===== OpenCLï¿½Rï¿½ï¿½ï¿½eï¿½Lï¿½Xï¿½gï¿½ï¿½E2Eï¿½ï¿½ï¿½fï¿½ï¿½ï¿½Ìï¿½ï¿½ï¿½ï¿½ï¿½ =====
    try:
        cloudlog.warning("setting up CL context")
        cl_context = CLContext()  # OpenCLï¿½ï¿½ï¿½sï¿½Rï¿½ï¿½ï¿½eï¿½Lï¿½Xï¿½gï¿½iGPUï¿½ï¿½ï¿½ï¿½ï¿½pï¿½j
        cloudlog.warning("CL context ready; loading E2E model")
        model = E2EModelState(cl_context)  # E2Eï¿½ï¿½ï¿½fï¿½ï¿½ï¿½Ìï¿½ï¿½ï¿½ï¿½ï¿½
        cloudlog.warning("E2E model loaded, e2emodeld starting")
    except Exception as e:
        cloudlog.error(f"Failed to initialize E2E model: {e}")
        import traceback

        cloudlog.error(
            f"E2E model initialization error traceback: {traceback.format_exc()}"
        )
        raise

    # ===== ï¿½Jï¿½ï¿½ï¿½ï¿½ï¿½Nï¿½ï¿½ï¿½Cï¿½Aï¿½ï¿½ï¿½gï¿½Ìİ’ï¿½iï¿½Vï¿½~ï¿½ï¿½ï¿½ï¿½ï¿½[ï¿½^ï¿½Eï¿½ï¿½ï¿½@ï¿½Î‰ï¿½ï¿½j =====
    try:
        cloudlog.warning("Setting up vision clients...")

        # ï¿½Jï¿½ï¿½ï¿½ï¿½ï¿½Xï¿½gï¿½ï¿½ï¿½[ï¿½ï¿½ï¿½Ìï¿½ï¿½ï¿½ï¿½ï¿½ï¿½oï¿½iï¿½Â‹ï¿½ï¿½É‰ï¿½ï¿½ï¿½ï¿½Ä“Kï¿½ï¿½ï¿½j
        timeout_count = 0
        max_timeout = 50  # 5ï¿½bï¿½Ô‚Ìï¿½ï¿½s

        while True:
            available_streams = VisionIpcClient.available_streams(
                "camerad", block=False
            )
            if available_streams:
                use_extra_client = (
                    VisionStreamType.VISION_STREAM_WIDE_ROAD in available_streams
                    and VisionStreamType.VISION_STREAM_ROAD in available_streams
                )
                main_wide_camera = (
                    VisionStreamType.VISION_STREAM_ROAD not in available_streams
                )
                break

            timeout_count += 1
            if timeout_count >= max_timeout:
                cloudlog.error("?? Timeout waiting for camera streams")
                if demo:
                    cloudlog.warning(
                        "?? Demo mode: Proceeding without camera streams (may use dummy data)"
                    )
                    # ï¿½fï¿½ï¿½ï¿½ï¿½ï¿½[ï¿½hï¿½Å‚Í‘ï¿½ï¿½sï¿½ï¿½ï¿½ï¿½ï¿½ï¿½
                    available_streams = []
                    use_extra_client = False
                    main_wide_camera = True
                    break
                else:
                    raise RuntimeError("Camera streams not available in real mode")

            time.sleep(0.1)

        vipc_client_main_stream = (
            VisionStreamType.VISION_STREAM_WIDE_ROAD
            if main_wide_camera
            else VisionStreamType.VISION_STREAM_ROAD
        )
        vipc_client_main = VisionIpcClient(
            "camerad", vipc_client_main_stream, True, cl_context
        )
        vipc_client_extra = VisionIpcClient(
            "camerad", VisionStreamType.VISION_STREAM_WIDE_ROAD, False, cl_context
        )
        cloudlog.warning(
            f"?? Vision config: main_wide_camera={main_wide_camera}, use_extra_client={use_extra_client}"
        )

        while not vipc_client_main.connect(False):
            time.sleep(0.1)
        while not vipc_client_extra.connect(False):
            time.sleep(0.1)

        # ï¿½Ú‘ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ÌŠmï¿½F
        if vipc_client_main.connect(False):
            cloudlog.warning(
                f"? Main camera connected: {vipc_client_main.buffer_len} buffers "
            )
        if use_extra_client and vipc_client_extra.connect(False):
            cloudlog.warning(
                f"? Extra camera connected: {vipc_client_extra.buffer_len} buffers "
            )

    except Exception as e:
        cloudlog.error(f"Failed to setup vision clients: {e}")
        if demo:
            cloudlog.warning("?? Demo mode: Continuing despite vision setup failure")
            vipc_client_main = None
            vipc_client_extra = None
            use_extra_client = False
            main_wide_camera = True
        else:
            raise

    try:
        pm = PubMaster(["e2eOutput"])
        sm = SubMaster(["carState", "navInstruction"])
    except Exception as e:
        cloudlog.error(f"Failed to setup messaging: {e}")
        raise

    params = Params()

    # setup filter to track dropped frames
    frame_dropped_filter = FirstOrderFilter(0.0, 10.0, 1.0 / ModelConstants.MODEL_FREQ)
    last_vipc_frame_id = 0
    run_count = 0
    live_calib_seen = False
    nav_instructions = np.zeros(ModelConstants.NAV_INSTRUCTION_LEN, dtype=np.float32)
    buf_main, buf_extra = None, None
    meta_main = FrameMeta()
    meta_extra = FrameMeta()

    if demo:
        CP = get_demo_car_params()
    else:
        with car.CarParams.from_bytes(params.get("CarParams", block=True)) as msg:
            CP = msg
    cloudlog.info("e2emodeld got CarParams: %s", CP.carName)

    DH = DesireHelper()

    cloudlog.warning("E2E model main loop starting")

    # E2Eï¿½ï¿½pï¿½ÌXï¿½Vï¿½pï¿½xï¿½ï¿½ï¿½ï¿½Æƒtï¿½ï¿½ï¿½[ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½
    last_e2e_update_time = 0.0
    e2e_update_interval = 1.0 / E2E_MODEL_FREQ  # 10Hzï¿½ÔŠu
    loop_count = 0  # ï¿½ï¿½ï¿½[ï¿½vï¿½Jï¿½Eï¿½ï¿½ï¿½^ï¿½[ï¿½Ç‰ï¿½

    while True:
        current_time = time.monotonic()
        loop_count += 1

        if loop_count % 100 == 1:
            with open("/tmp/e2e_car_state_debug.log", "a") as f:
                import time as time_module

                f.write(f"{time_module.time()}: Main loop iteration {loop_count}\n")
                f.flush()

        # E2Eï¿½Xï¿½Vï¿½pï¿½xï¿½ï¿½ï¿½ï¿½
        if current_time - last_e2e_update_time < e2e_update_interval:
            time.sleep(0.001)
            continue

        # ===== ï¿½Jï¿½ï¿½ï¿½ï¿½ï¿½tï¿½ï¿½ï¿½[ï¿½ï¿½ï¿½æ“¾ =====
        try:
            # ï¿½ï¿½ï¿½Cï¿½ï¿½ï¿½Jï¿½ï¿½ï¿½ï¿½ï¿½tï¿½ï¿½ï¿½[ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½
            cloudlog.debug(
                f"Attempting to receive main frame, meta_main.timestamp: {meta_main.timestamp_sof}, meta_extra.timestamp: {meta_extra.timestamp_sof}"
            )

            # Keep receiving frames until we are at least 1 frame ahead of previous extra frame
            recv_attempts = 0
            max_attempts = 10  # ï¿½ï¿½ï¿½sï¿½ñ”‚ğ‘‰ï¿½

            while (
                meta_main.timestamp_sof < meta_extra.timestamp_sof + 25000000
                and recv_attempts < max_attempts
            ):
                buf_main = vipc_client_main.recv()
                meta_main = FrameMeta(vipc_client_main)
                recv_attempts += 1
                if buf_main is None:
                    time.sleep(0.02)
                    continue
                else:
                    break

            # ï¿½Ç‰ï¿½ï¿½Jï¿½ï¿½ï¿½ï¿½ï¿½tï¿½ï¿½ï¿½[ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½
            if use_extra_client:

                # Keep receiving extra frames until frame id matches main camera
                extra_recv_attempts = 0
                max_extra_attempts = 3
                while extra_recv_attempts < max_extra_attempts:
                    buf_extra = vipc_client_extra.recv()
                    meta_extra = FrameMeta(vipc_client_extra)
                    extra_recv_attempts += 1
                    if (
                        buf_extra is None
                        or meta_main.timestamp_sof < meta_extra.timestamp_sof + 25000000
                    ):
                        break

                # ï¿½tï¿½ï¿½ï¿½[ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½`ï¿½Fï¿½bï¿½N
                if abs(meta_main.timestamp_sof - meta_extra.timestamp_sof) > 10000000:
                    cloudlog.warning(
                        "frames out of sync! main: {} ({:.5f}), extra: {} ({:.5f})".format(
                            meta_main.frame_id,
                            meta_main.timestamp_sof / 1e9,
                            meta_extra.frame_id,
                            meta_extra.timestamp_sof / 1e9,
                        )
                    )

            else:
                # ï¿½Vï¿½ï¿½ï¿½Oï¿½ï¿½ï¿½Jï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½[ï¿½h
                buf_extra = buf_main
                meta_extra = meta_main

        except Exception as e:
            cloudlog.error(f"Camera frame processing error: {e}")

        sm.update(0)

        try:
            car_state_msg = sm["carState"]
            car_state_valid = sm.valid["carState"]
            car_state_updated = sm.updated["carState"]

            if car_state_msg is not None:
                basic_attrs = [
                    "vEgo",
                    "aEgo",
                    "steeringAngleDeg",
                    "leftBlinker",
                    "rightBlinker",
                ]
                car_state_input = {}
                for attr in basic_attrs:
                    if hasattr(car_state_msg, attr):
                        value = getattr(car_state_msg, attr)
                        car_state_input[attr] = value
                        print(f"   {attr}: {value} (exists)", flush=True)
                    else:
                        print(f"   {attr}: NOT FOUND", flush=True)
                update_car_state_queue(car_state_input)
            else:
                print("? carState message is None!", flush=True)

            # ï¿½tï¿½@ï¿½Cï¿½ï¿½ï¿½ï¿½ï¿½Oï¿½É‚ï¿½ï¿½Lï¿½^
            with open("/tmp/e2e_carstate_message_debug.log", "a") as f:
                import time as time_module

                f.write(
                    f"{time_module.time()}: CarState Message - Valid:{car_state_valid}, Updated:{car_state_updated}, Type:{type(car_state_msg).__name__}\n"
                )
                f.flush()

        except Exception as debug_error:
            print(f"? CAR STATE MESSAGE DEBUG ERROR: {debug_error}", flush=True)

        desire = DH.desire
        is_rhd = True  # ï¿½Eï¿½nï¿½ï¿½ï¿½hï¿½ï¿½ï¿½Ô‚Æ‚ï¿½ï¿½Äİ’ï¿½

        if not live_calib_seen:
            live_calib_seen = True

        traffic_convention = np.zeros(2)
        traffic_convention[int(is_rhd)] = 1

        vec_desire = np.zeros(ModelConstants.DESIRE_LEN, dtype=np.float32)
        if desire >= 0 and desire < ModelConstants.DESIRE_LEN:
            vec_desire[desire] = 1

        nav_valid = sm.valid["navInstruction"]
        nav_enabled = nav_valid

        if not nav_enabled:
            nav_instructions[:] = 0

        if nav_enabled and sm.updated["navInstruction"]:
            nav_instructions[:] = 0
            maneuver_processed = 0
            for maneuver in sm["navInstruction"].allManeuvers:
                distance_idx = 25 + int(maneuver.distance / 20)
                direction_idx = 0
                if maneuver.modifier in ("left", "slight left", "sharp left"):
                    direction_idx = 1
                if maneuver.modifier in ("right", "slight right", "sharp right"):
                    direction_idx = 2
                if 0 <= distance_idx < 50:
                    final_idx = distance_idx * 3 + direction_idx
                    nav_instructions[final_idx] = 1
                    maneuver_processed += 1

        # tracked dropped frames
        vipc_dropped_frames = max(0, meta_main.frame_id - last_vipc_frame_id - 1)
        if run_count < 10:  # let frame drops warm up
            frame_dropped_filter.x = 0.0
        run_count = run_count + 1

        prepare_only = vipc_dropped_frames > 0
        if prepare_only:
            cloudlog.error(
                f"skipping E2E model eval. Dropped {vipc_dropped_frames} frames"
            )

        inputs: Dict[str, np.ndarray] = {
            "carState": sm["carState"],
            "nav_instructions": nav_instructions,
        }

        mt1 = time.perf_counter()
        model_output = model.run(buf_main, buf_extra, inputs)
        mt2 = time.perf_counter()
        model_execution_time = mt2 - mt1

        if model_output is not None:
            cloudlog.debug(f"E2E model execution time: {model_execution_time:.4f}s")

            try:
                pred_vEgo = model_output["pred_vEgo"]
                pred_aEgo = model_output["pred_aEgo"]
                pred_steeringAngleDeg = model_output["pred_steeringAngleDeg"]

                cloudlog.debug("E2E ONNX model predictions")
                cloudlog.debug(f"steer: {pred_steeringAngleDeg:.6f} Deg")
                cloudlog.debug(f"acc: {pred_aEgo:.6f} m/s2, vel: {pred_vEgo:.6f} m/s")
                cloudlog.debug(f"execTime: {model_execution_time:.3f}ms")

                # ï¿½Ú×ƒfï¿½oï¿½bï¿½O: ï¿½ï¿½ï¿½fï¿½ï¿½ï¿½oï¿½Í’lï¿½ï¿½ï¿½tï¿½@ï¿½Cï¿½ï¿½ï¿½É‚ï¿½ï¿½Lï¿½^
                debug_msg = f"steer={pred_steeringAngleDeg:.6f}, acc={pred_aEgo:.6f}, vel={pred_vEgo:.6f}, execTime={model_execution_time:.3f}ms"
                import time as time_module

                with open("/tmp/e2e_model_output_debug.log", "a") as f:
                    f.write(f"{time_module.time()}: {debug_msg}\n")

                # rlogï¿½É‹Lï¿½^ï¿½ï¿½ï¿½é‚½ï¿½ß‚Ìƒï¿½ï¿½bï¿½Zï¿½[ï¿½Wï¿½ï¿½ï¿½M
                if pm is not None:
                    import cereal.messaging as messaging

                    # e2eOutputï¿½ï¿½ï¿½bï¿½Zï¿½[ï¿½W
                    e2e_out_msg = messaging.new_message("e2eOutput")
                    e2e_out_msg.e2eOutput.aEgo = pred_aEgo
                    e2e_out_msg.e2eOutput.vEgo = pred_vEgo
                    e2e_out_msg.e2eOutput.steeringAngleDeg = pred_steeringAngleDeg
                    e2e_out_msg.e2eOutput.timestamp = int(time.time_ns())
                    e2e_out_msg.e2eOutput.isValid = True
                    # ï¿½dï¿½v: ï¿½ï¿½ï¿½bï¿½Zï¿½[ï¿½Wï¿½ï¿½ï¿½xï¿½ï¿½ï¿½ï¿½validï¿½tï¿½ï¿½ï¿½Oï¿½ï¿½ï¿½İ’ï¿½
                    e2e_out_msg.valid = True
                    pm.send("e2eOutput", e2e_out_msg)

                # E2Eï¿½Xï¿½Vï¿½ï¿½ï¿½Ô‚ï¿½ï¿½Lï¿½^
                last_e2e_update_time = current_time

            except Exception as e:
                cloudlog.error(f"Error processing E2E model output: {e}")
                import traceback

                cloudlog.error(f"E2E error traceback: {traceback.format_exc()}")

                # ï¿½Gï¿½ï¿½ï¿½[ï¿½ï¿½ï¿½Å‚ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Èƒï¿½ï¿½bï¿½Zï¿½[ï¿½Wï¿½ğ‘—M
                try:
                    e2e_out_msg = messaging.new_message("e2eOutput")
                    e2e_out_msg.e2eOutput.aEgo = 0.0
                    e2e_out_msg.e2eOutput.vEgo = 0.0
                    e2e_out_msg.e2eOutput.steeringAngleDeg = 0.0
                    e2e_out_msg.e2eOutput.timestamp = int(time.time_ns())
                    e2e_out_msg.e2eOutput.isValid = False
                    # ï¿½Gï¿½ï¿½ï¿½[ï¿½ï¿½: ï¿½ï¿½ï¿½bï¿½Zï¿½[ï¿½Wï¿½ï¿½ï¿½xï¿½ï¿½ï¿½ï¿½validï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Éİ’ï¿½
                    e2e_out_msg.valid = False
                    pm.send("e2eOutput", e2e_out_msg)
                    cloudlog.debug("E2E error: sent invalid message")
                except Exception as msg_error:
                    cloudlog.error(f"Failed to send error message: {msg_error}")

        # ï¿½tï¿½ï¿½ï¿½[ï¿½ï¿½IDï¿½ÌXï¿½Vï¿½iï¿½ï¿½ï¿½ï¿½Ìƒtï¿½ï¿½ï¿½[ï¿½ï¿½ï¿½hï¿½ï¿½ï¿½bï¿½vï¿½ï¿½ï¿½oï¿½pï¿½j
        last_vipc_frame_id = meta_main.frame_id


# ===== ï¿½ï¿½ï¿½Cï¿½ï¿½ï¿½ï¿½ï¿½sï¿½ï¿½ =====
if __name__ == "__main__":
    """
    E2Eï¿½ï¿½ï¿½fï¿½ï¿½ï¿½fï¿½[ï¿½ï¿½ï¿½ï¿½ï¿½ÌƒGï¿½ï¿½ï¿½gï¿½ï¿½ï¿½[ï¿½|ï¿½Cï¿½ï¿½ï¿½g

    ï¿½Rï¿½}ï¿½ï¿½ï¿½hï¿½ï¿½ï¿½Cï¿½ï¿½ï¿½ï¿½ï¿½ï¿½:
      --demo: ï¿½fï¿½ï¿½ï¿½ï¿½ï¿½[ï¿½hï¿½iCarParamsï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Aï¿½ï¿½ï¿½Ô‚È‚ï¿½ï¿½Åƒeï¿½Xï¿½gï¿½Â”\ï¿½j

    ï¿½ï¿½ï¿½sï¿½ï¿½:
      python selfdrive/modeld/e2emodeld.py          # ï¿½Êíƒ‚ï¿½[ï¿½h
      python selfdrive/modeld/e2emodeld.py --demo   # ï¿½fï¿½ï¿½ï¿½ï¿½ï¿½[ï¿½h
    """
    try:
        # ï¿½Rï¿½}ï¿½ï¿½ï¿½hï¿½ï¿½ï¿½Cï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ì‰ï¿½ï¿½
        import argparse

        parser = argparse.ArgumentParser(description="E2Eï¿½ï¿½ï¿½ï¿½ï¿½^ï¿½]ï¿½ï¿½ï¿½fï¿½ï¿½ï¿½ï¿½ï¿½sï¿½fï¿½[ï¿½ï¿½ï¿½ï¿½")
        parser.add_argument(
            "--demo",
            action="store_true",
            help="ï¿½fï¿½ï¿½ï¿½ï¿½ï¿½[ï¿½hï¿½iCarParamsï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Aï¿½ï¿½ï¿½ÔÚ‘ï¿½ï¿½sï¿½vï¿½j",
        )
        args = parser.parse_args()

        # ï¿½ï¿½ï¿½Cï¿½ï¿½ï¿½Öï¿½ï¿½Ìï¿½ï¿½s
        main(demo=args.demo)

    except KeyboardInterrupt:
        # Ctrl+Cï¿½É‚ï¿½é³ï¿½ï¿½Iï¿½ï¿½
        cloudlog.warning(f"child {PROCESS_NAME} got SIGINT")
    except Exception:
        # ï¿½\ï¿½ï¿½ï¿½ï¿½ï¿½È‚ï¿½ï¿½Gï¿½ï¿½ï¿½[ï¿½Ìê‡ï¿½ASentryï¿½É‘ï¿½ï¿½Mï¿½ï¿½ï¿½ÄÄ”ï¿½ï¿½ï¿½
        sentry.capture_exception()
        raise