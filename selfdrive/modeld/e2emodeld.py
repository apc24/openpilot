#!/usr/bin/env python3
"""
E2E (End-to-End) è‡ªå‹•é‹è»¢ãƒ¢ãƒ‡ãƒ«å®Ÿè¡Œãƒ‡ãƒ¼ãƒ¢ãƒ³
"""

import os
import time
import numpy as np
# import cv2
from cereal import car
from pathlib import Path
from typing import Dict, List, Optional
from setproctitle import setproctitle
from cereal.messaging import PubMaster, SubMaster
# from cereal.visionipc import VisionIpcClient, VisionStreamType, VisionBuf
import onnxruntime as ort
from openpilot.common.swaglog import cloudlog
from openpilot.common.params import Params
from openpilot.common.filter_simple import FirstOrderFilter
from openpilot.common.realtime import config_realtime_process
from openpilot.selfdrive import sentry
from openpilot.selfdrive.car.car_helpers import get_demo_car_params
from openpilot.selfdrive.controls.lib.desire_helper import DesireHelper
from openpilot.selfdrive.modeld.runners import ModelRunner
from openpilot.selfdrive.modeld.constants import ModelConstants
from openpilot.selfdrive.modeld.models.commonmodel_pyx import ModelFrame, CLContext
from collections import deque

# ===== ãƒ—ãƒ­ã‚»ã‚¹è¨­å®š =====
PROCESS_NAME = "selfdrive.modeld.e2emodeld"
SEND_RAW_PRED = os.getenv("SEND_RAW_PRED")  # ãƒ‡ãƒãƒƒã‚°ç”¨: ç”Ÿã®äºˆæ¸¬å€¤é€ä¿¡ãƒ•ãƒ©ã‚°
SEND_E2E_OUTPUT = os.getenv(
    "SEND_E2E_OUTPUT", "1"
)  # E2Eå‡ºåŠ›ã‚’å¸¸ã«é€ä¿¡ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæœ‰åŠ¹ï¼‰ 

# ===== ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹è¨­å®š =====
# ã‚«ã‚¹ã‚¿ãƒ å­¦ç¿’æ¸ˆã¿E2Eãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹è¨­å®š
MODEL_PATHS = {
    ModelRunner.ONNX: Path(__file__).parent
    # / "models/checkpoint_epoch_57_best.onnx"  # v2.1 Transformer
    # / "models/checkpoint_epoch_90_best.onnx"  # v2.1 LSTM
    / "models/v2.2_lstm.onnx"  # v2.2 LSTM

}

E2E_MODEL_FREQ = 10.0  # 10Hz
IMAGE_SIZE = 224

# æ–°ã—ã„carStateã®æ¬¡å…ƒã‚’å®šç¾©
CAR_STATE_DIM = 5
PREDICTION_HORIZON = 10

car_state_queue: deque = deque(maxlen=120)


def update_car_state_queue(car_state_data):
    timestamp = time.time()
    car_state_entry = {
        "timestamp": timestamp,
        "vEgo": car_state_data.get("vEgo", 0.0),
        "aEgo": car_state_data.get("aEgo", 0.0),
        "steeringAngleDeg": car_state_data.get("steeringAngleDeg", 0.0),
        "leftBlinker": car_state_data.get("leftBlinker", False),
        "rightBlinker": car_state_data.get("rightBlinker", False),
    }
    car_state_queue.append(car_state_entry)


def get_past_car_state_data(queue, step=0.5, steps=10):
    current_time = time.time()
    past_data = {
        "vEgos": [],
        "aEgos": [],
        "steeringAngleDegs": [],
        "leftBlinkers": [],
        "rightBlinkers": [],
    }

    for i in range(steps):
        target_time = current_time - (i * step)
        closest_entry = min(queue, key=lambda x: abs(x["timestamp"] - target_time))
        past_data["vEgos"].append(closest_entry["vEgo"])
        past_data["aEgos"].append(closest_entry["aEgo"])
        past_data["steeringAngleDegs"].append(closest_entry["steeringAngleDeg"])
        past_data["leftBlinkers"].append(1 if closest_entry["leftBlinker"] else 0)
        past_data["rightBlinkers"].append(1 if closest_entry["rightBlinker"] else 0)

    return past_data


# def process_camera_frame(buf: VisionBuf) -> np.ndarray:
#     """
#     VisionBufã‹ã‚‰å®Ÿéš›ã®ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€E2Eãƒ¢ãƒ‡ãƒ«ç”¨ã«å‰å‡¦ç†ã‚’å®Ÿè¡Œ
#     """
#     try:
#         # VisionBufã®æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯
#         if buf is None:
#             cloudlog.warning("VisionBuf is None, using dummy image")
#             return np.zeros((3, IMAGE_SIZE, IMAGE_SIZE), dtype=np.float32)

#         # YUV420: Y(è¼åº¦) + U/V(è‰²å·®)ãŒç¸¦æ–¹å‘ã«1.5å€ã®ã‚µã‚¤ã‚ºã§æ ¼ç´
#         yuv_img = np.frombuffer(buf.data, dtype=np.uint8).reshape(
#             (buf.height + buf.height // 2, buf.width)
#         )

#         # YUV420ã‚’RGBã«å¤‰æ›
#         rgb_img = cv2.cvtColor(yuv_img, cv2.COLOR_YUV2RGB_I420)

#         # ç”»åƒã®ãƒªã‚µã‚¤ã‚º (å…ƒè§£åƒåº¦ â†’ 224x224)
#         resized_img = cv2.resize(
#             rgb_img, (IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_LINEAR
#         )

#         # [0, 255] â†’ [0, 1] æ­£è¦åŒ–
#         normalized_img = resized_img.astype(np.float32) / 255.0

#         # HWC â†’ CHW (Height, Width, Channel â†’ Channel, Height, Width)
#         # PyTorchãƒ¢ãƒ‡ãƒ«ã®å…¥åŠ›å½¢å¼ã«å¤‰æ›
#         transposed_img = normalized_img.transpose(2, 0, 1)

#         return transposed_img

#     except Exception as e:
#         cloudlog.error(f"Error processing camera frame: {e}")
#         # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ã‚¼ãƒ­ã§åŸ‹ã‚ãŸãƒ€ãƒŸãƒ¼ç”»åƒã‚’è¿”ã™
#         return np.zeros((3, IMAGE_SIZE, IMAGE_SIZE), dtype=np.float32)


class FrameMeta:
    """
    ã‚«ãƒ¡ãƒ©ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹

    ãƒ•ãƒ¬ãƒ¼ãƒ IDã€ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãªã©ã®æƒ…å ±ã‚’æ ¼ç´ã—ã€
    ãƒ•ãƒ¬ãƒ¼ãƒ åŒæœŸã‚„ãƒ‰ãƒ­ãƒƒãƒ—ãƒ•ãƒ¬ãƒ¼ãƒ æ¤œå‡ºã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚
    """

    frame_id: int = 0  # ãƒ•ãƒ¬ãƒ¼ãƒ é€šç•ª
    timestamp_sof: int = 0  # ãƒ•ãƒ¬ãƒ¼ãƒ é–‹å§‹æ™‚åˆ»ï¼ˆnanosecondï¼‰
    timestamp_eof: int = 0  # ãƒ•ãƒ¬ãƒ¼ãƒ çµ‚äº†æ™‚åˆ»ï¼ˆnanosecondï¼‰

    def __init__(self, vipc=None):
        """
        VisionIpcClientã‹ã‚‰ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’åˆæœŸåŒ–

        Args:
          vipc: VisionIpcClient - ã‚«ãƒ¡ãƒ©ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆNoneã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ï¼‰
        """
        if vipc is not None:
            self.frame_id, self.timestamp_sof, self.timestamp_eof = (
                vipc.frame_id,
                vipc.timestamp_sof,
                vipc.timestamp_eof,
            )


# class E2EModelState:
#     """
#     E2Eï¼ˆEnd-to-Endï¼‰ãƒ¢ãƒ‡ãƒ«ã®çŠ¶æ…‹ã¨ãƒ‡ãƒ¼ã‚¿ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹
#     """

#     # ã‚¯ãƒ©ã‚¹å±æ€§ã®å‹ãƒ’ãƒ³ãƒˆ
#     frame: ModelFrame  # ãƒ¡ã‚¤ãƒ³ã‚«ãƒ¡ãƒ©ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ç”¨
#     wide_frame: ModelFrame  # ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ¡ãƒ©ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ç”¨
#     session: ort.InferenceSession  # ONNXãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚»ãƒƒã‚·ãƒ§ãƒ³
#     inputs: Dict[str, np.ndarray]  # ãƒ¢ãƒ‡ãƒ«å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
#     output: Dict[str, float]  # ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿

#     def __init__(self, context: CLContext):
#         """
#         E2EModelStateã®åˆæœŸåŒ–
#         """
#         # ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ç”¨ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®åˆæœŸåŒ–
#         self.frame = ModelFrame(context)  # ãƒ¡ã‚¤ãƒ³ã‚«ãƒ¡ãƒ©ç”¨
#         self.wide_frame = ModelFrame(context)  # ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ¡ãƒ©ç”¨

#         self.session = ort.InferenceSession(
#             MODEL_PATHS[ModelRunner.ONNX].as_posix(), providers=["CPUExecutionProvider"]
#         )

#         self.inputs = {
#             "mainCamera": np.zeros((1, 3, 224, 224), dtype=np.float32),
#             "zoomCamera": np.zeros((1, 3, 224, 224), dtype=np.float32),
#             "navVector": np.zeros((1, 150), dtype=np.float32),
#             "carState": np.zeros((1, CAR_STATE_DIM, PREDICTION_HORIZON), dtype=np.float32),  # çµ±åˆã•ã‚ŒãŸcarState
#         }

#         self.output = {
#             "pred_vEgo": float(0.0),
#             "pred_aEgo": float(0.0),
#             "pred_steeringAngleDeg": float(0.0),
#         }

#     def run(
#         self, buf: VisionBuf, wbuf: VisionBuf, inputs: Dict[str, np.ndarray]
#     ) -> Optional[Dict[str, float|List[float]]]:
#         """
#         E2Eãƒ¢ãƒ‡ãƒ«ã®æ¨è«–å®Ÿè¡Œãƒ¡ã‚¤ãƒ³é–¢æ•°
#         """

#         try:
#             main_camera_input = process_camera_frame(buf)
#             zoom_camera_input = process_camera_frame(wbuf)
#             self.inputs["mainCamera"] = np.expand_dims(main_camera_input, axis=0)
#             self.inputs["zoomCamera"] = np.expand_dims(zoom_camera_input, axis=0)
#         except Exception as e:
#             cloudlog.error(f"Error processing camera inputs: {e}")

#         try:
#             # çµ±åˆã•ã‚ŒãŸcarStateã‚’ä½œæˆ
#             past_car_state_data = get_past_car_state_data(car_state_queue, step=0.5, steps=PREDICTION_HORIZON)
#             car_state_tensor = np.stack([
#                 np.array(past_car_state_data["vEgos"], dtype=np.float32) / 10,  # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
#                 np.array(past_car_state_data["aEgos"], dtype=np.float32),
#                 np.array(past_car_state_data["steeringAngleDegs"], dtype=np.float32) / 100,  # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
#                 np.array(past_car_state_data["leftBlinkers"], dtype=np.float32),
#                 np.array(past_car_state_data["rightBlinkers"], dtype=np.float32),
#             ], axis=0)  # (CAR_STATE_DIM, PREDICTION_HORIZON)

#             self.inputs["carState"] = np.expand_dims(car_state_tensor, axis=0)  # (1, CAR_STATE_DIM, PREDICTION_HORIZON)
#         except Exception as e:
#             cloudlog.error(f"Error processing carState input: {e}")

#         try:
#             self.inputs["navVector"] = np.expand_dims(inputs.get(
#                 "navVector", np.zeros(150, dtype=np.float32)
#             ), axis=0)
#         except Exception as e:
#             cloudlog.error(f"Error processing navVector input: {e}")

#         pred_vEgos, pred_aEgos, pred_steeringAngleDegs = self.session.run(None, self.inputs)
#         vEgos_plan: List[float] = (pred_vEgos[0] * 10.0).tolist()  # m/sã«ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
#         self.output["pred_vEgo"] = vEgos_plan[0]
#         self.output["pred_aEgo"] = float(pred_aEgos[0][0])
#         self.output["pred_steeringAngleDeg"] = float(pred_steeringAngleDegs[0][0] * 100.0)  # degã«ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
#         self.output["vEgos_plan"] = vEgos_plan
#         return self.output


def main(demo=False):
    """
    E2Eãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ¼ãƒ¢ãƒ³ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°
    """
    cloudlog.warning("e2emodeld init")

    # ===== ãƒ—ãƒ­ã‚»ã‚¹è¨­å®šã®åˆæœŸåŒ– =====
    sentry.set_tag("daemon", PROCESS_NAME)  # Sentryã‚¨ãƒ©ãƒ¼è¿½è·¡ç”¨ã‚¿ã‚°è¨­å®š
    cloudlog.bind(daemon=PROCESS_NAME)  # ãƒ­ã‚°ã«ãƒ—ãƒ­ã‚»ã‚¹åã‚’ãƒã‚¤ãƒ³ãƒ‰
    setproctitle(PROCESS_NAME)  # ãƒ—ãƒ­ã‚»ã‚¹åã‚’è¨­å®šï¼ˆpsã‚³ãƒãƒ³ãƒ‰ã§ç¢ºèªå¯èƒ½ï¼‰
    config_realtime_process(7, 54)  # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ—ãƒ­ã‚»ã‚¹è¨­å®šï¼ˆCPU7ç•ªã€å„ªå…ˆåº¦54ï¼‰

    # ===== OpenCLã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨E2Eãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ– =====
    try:
        cloudlog.warning("setting up CL context")
        cl_context = CLContext()  # OpenCLå®Ÿè¡Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆGPUå‡¦ç†ç”¨ï¼‰
        cloudlog.warning("CL context ready; loading E2E model")
        #æ¤œè¨¼ã®ãŸã‚ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
        # model = E2EModelState(cl_context)  # E2Eãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
        cloudlog.warning("E2E model loaded, e2emodeld starting")
    except Exception as e:
        cloudlog.error(f"Failed to initialize E2E model: {e}")
        import traceback

        cloudlog.error(
            f"E2E model initialization error traceback: {traceback.format_exc()}"
        )
        raise

    # ===== ã‚«ãƒ¡ãƒ©ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®è¨­å®šï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ»å®Ÿæ©Ÿå¯¾å¿œï¼‰ =====
    # try:
    #     cloudlog.warning("Setting up vision clients...")

    #     # ã‚«ãƒ¡ãƒ©ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®è‡ªå‹•æ¤œå‡ºï¼ˆç’°å¢ƒã«å¿œã˜ã¦é©å¿œï¼‰
    #     timeout_count = 0
    #     max_timeout = 50  # 5ç§’é–“ã®è©¦è¡Œ

    #     while True:
    #         available_streams = VisionIpcClient.available_streams(
    #             "camerad", block=False
    #         )
    #         if available_streams:
    #             use_extra_client = (
    #                 VisionStreamType.VISION_STREAM_WIDE_ROAD in available_streams
    #                 and VisionStreamType.VISION_STREAM_ROAD in available_streams
    #             )
    #             main_wide_camera = (
    #                 VisionStreamType.VISION_STREAM_ROAD not in available_streams
    #             )
    #             break

    #         timeout_count += 1
    #         if timeout_count >= max_timeout:
    #             cloudlog.error("âš ï¸ Timeout waiting for camera streams")
    #             if demo:
    #                 cloudlog.warning(
    #                     "ğŸ® Demo mode: Proceeding without camera streams (may use dummy data)"
    #                 )
    #                 # ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ã§ã¯ç¶šè¡Œã‚’è¨±å¯
    #                 available_streams = []
    #                 use_extra_client = False
    #                 main_wide_camera = True
    #                 break
    #             else:
    #                 raise RuntimeError("Camera streams not available in real mode")

    #         time.sleep(0.1)

    #     vipc_client_main_stream = (
    #         VisionStreamType.VISION_STREAM_WIDE_ROAD
    #         if main_wide_camera
    #         else VisionStreamType.VISION_STREAM_ROAD
    #     )
    #     vipc_client_main = VisionIpcClient(
    #         "camerad", vipc_client_main_stream, True, cl_context
    #     )
    #     vipc_client_extra = VisionIpcClient(
    #         "camerad", VisionStreamType.VISION_STREAM_WIDE_ROAD, False, cl_context
    #     )
    #     cloudlog.warning(
    #         f"ğŸ“· Vision config: main_wide_camera={main_wide_camera}, use_extra_client={use_extra_client}"
    #     )

    #     while not vipc_client_main.connect(False):
    #         time.sleep(0.1)
    #     while not vipc_client_extra.connect(False):
    #         time.sleep(0.1)

    #     # æ¥ç¶šæˆåŠŸã®ç¢ºèª
    #     if vipc_client_main.connect(False):
    #         cloudlog.warning(
    #             f"âœ… Main camera connected: {vipc_client_main.buffer_len} buffers "
    #         )
    #     if use_extra_client and vipc_client_extra.connect(False):
    #         cloudlog.warning(
    #             f"âœ… Extra camera connected: {vipc_client_extra.buffer_len} buffers "
    #         )

    # except Exception as e:
    #     cloudlog.error(f"Failed to setup vision clients: {e}")
    #     if demo:
    #         cloudlog.warning("ğŸ® Demo mode: Continuing despite vision setup failure")
    #         vipc_client_main = None
    #         vipc_client_extra = None
    #         use_extra_client = False
    #         main_wide_camera = True
    #     else:
    #         raise

    # try:
    #     pm = PubMaster(["e2eOutput"])
    #     sm = SubMaster(["carState", "navInstruction"])
    # except Exception as e:
    #     cloudlog.error(f"Failed to setup messaging: {e}")
    #     raise


    if demo:
        CP = get_demo_car_param
    # params = Params()

    # # setup filter to track dropped frames
    # frame_dropped_filter = FirstOrderFilter(0.0, 10.0, 1.0 / ModelConstants.MODEL_FREQ)
    # last_vipc_frame_id = 0
    # run_count = 0
    # live_calib_seen = False
    # nav_instructions = np.zeros(ModelConstants.NAV_INSTRUCTION_LEN, dtype=np.float32)
    # buf_main, buf_extra = None, None
    # meta_main = FrameMeta()
    # meta_extra = FrameMeta()s()
    # else:
    #     with car.CarParams.from_bytes(params.get("CarParams", block=True)) as msg:
    #         CP = msg
    # cloudlog.info("e2emodeld got CarParams: %s", CP.carName)

    # DH = DesireHelper()

    cloudlog.warning("E2E model main loop starting")

    # E2Eå°‚ç”¨ã®æ›´æ–°é »åº¦åˆ¶å¾¡ã¨ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†
    last_e2e_update_time = 0.0
    e2e_update_interval = 1.0 / E2E_MODEL_FREQ  # 10Hzé–“éš”
    loop_count = 0  # ãƒ«ãƒ¼ãƒ—ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼è¿½åŠ 

    while True:
        current_time = time.monotonic()
        loop_count += 1

        # if loop_count % 100 == 1:
        #     with open("/tmp/e2e_car_state_debug.log", "a") as f:
        #         import time as time_module
        #
        #         f.write(f"{time_module.time()}: Main loop iteration {loop_count}\n")
        #         f.flush()

        # E2Eæ›´æ–°é »åº¦åˆ¶å¾¡
        if current_time - last_e2e_update_time < e2e_update_interval:
            # time.sleep(0.001)
            time.sleep(0.01)
            continue

        # ===== ã‚«ãƒ¡ãƒ©ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾— =====
        # try:
        #     # ãƒ¡ã‚¤ãƒ³ã‚«ãƒ¡ãƒ©ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†
        #     cloudlog.debug(
        #         f"Attempting to receive main frame, meta_main.timestamp: {meta_main.timestamp_sof}, meta_extra.timestamp: {meta_extra.timestamp_sof}"
        #     )

        #     # Keep receiving frames until we are at least 1 frame ahead of previous extra frame
        #     recv_attempts = 0
        #     max_attempts = 10  # è©¦è¡Œå›æ•°ã‚’å¢—åŠ 

        #     while (
        #         meta_main.timestamp_sof < meta_extra.timestamp_sof + 25000000
        #         and recv_attempts < max_attempts
        #     ):
        #         buf_main = vipc_client_main.recv()
        #         meta_main = FrameMeta(vipc_client_main)
        #         recv_attempts += 1
        #         if buf_main is None:
        #             time.sleep(0.02)
        #             continue
        #         else:
        #             break

        #     # è¿½åŠ ã‚«ãƒ¡ãƒ©ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†
        #     if use_extra_client:

        #         # Keep receiving extra frames until frame id matches main camera
        #         extra_recv_attempts = 0
        #         max_extra_attempts = 3
        #         while extra_recv_attempts < max_extra_attempts:
        #             buf_extra = vipc_client_extra.recv()
        #             meta_extra = FrameMeta(vipc_client_extra)
        #             extra_recv_attempts += 1
        #             if (
        #                 buf_extra is None
        #                 or meta_main.timestamp_sof < meta_extra.timestamp_sof + 25000000
        #             ):
        #                 break

        #         # ãƒ•ãƒ¬ãƒ¼ãƒ åŒæœŸãƒã‚§ãƒƒã‚¯
        #         if abs(meta_main.timestamp_sof - meta_extra.timestamp_sof) > 10000000:
        #             cloudlog.warning(
        #                 "frames out of sync! main: {} ({:.5f}), extra: {} ({:.5f})".format(
        #                     meta_main.frame_id,
        #                     meta_main.timestamp_sof / 1e9,
        #                     meta_extra.frame_id,
        #                     meta_extra.timestamp_sof / 1e9,
        #                 )
        #             )

        #     else:
        #         # ã‚·ãƒ³ã‚°ãƒ«ã‚«ãƒ¡ãƒ©ãƒ¢ãƒ¼ãƒ‰
        #         buf_extra = buf_main
        #         meta_extra = meta_main

        # except Exception as e:
        #     cloudlog.error(f"Camera frame processing error: {e}")

        # sm.update(0)

        # try:
        #     car_state_msg = sm["carState"]
        #     car_state_valid = sm.valid["carState"]
        #     car_state_updated = sm.updated["carState"]

        #     if car_state_msg is not None:
        #         basic_attrs = [
        #             "vEgo",
        #             "aEgo",
        #             "steeringAngleDeg",
        #             "leftBlinker",
        #             "rightBlinker",
        #         ]
        #         car_state_input = {}
        #         for attr in basic_attrs:
        #             if hasattr(car_state_msg, attr):
        #                 value = getattr(car_state_msg, attr)
        #                 car_state_input[attr] = value
        #                 print(f"   {attr}: {value} (exists)", flush=True)
        #             else:
        #                 print(f"   {attr}: NOT FOUND", flush=True)
        #         update_car_state_queue(car_state_input)
        #     else:
        #         print("âŒ carState message is None!", flush=True)

            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ã‚°ã«ã‚‚è¨˜éŒ²
            # with open("/tmp/e2e_carstate_message_debug.log", "a") as f:
            #     import time as time_module

            #     f.write(
            #         f"{time_module.time()}: CarState Message - Valid:{car_state_valid}, Updated:{car_state_updated}, Type:{type(car_state_msg).__name__}\n"
            #     )
            #     f.flush()

        # except Exception as debug_error:
        #     print(f"âŒ CAR STATE MESSAGE DEBUG ERROR: {debug_error}", flush=True)

        # desire = DH.desire
        # is_rhd = True  # å³ãƒãƒ³ãƒ‰ãƒ«è»Šã¨ã—ã¦è¨­å®š

        # if not live_calib_seen:
        #     live_calib_seen = True

        # traffic_convention = np.zeros(2)
        # traffic_convention[int(is_rhd)] = 1

        # vec_desire = np.zeros(ModelConstants.DESIRE_LEN, dtype=np.float32)
        # if desire >= 0 and desire < ModelConstants.DESIRE_LEN:
        #     vec_desire[desire] = 1

        # nav_valid = sm.valid["navInstruction"]
        # nav_enabled = nav_valid

        # if not nav_enabled:
        #     nav_instructions[:] = 0

        # if nav_enabled and sm.updated["navInstruction"]:
        #     nav_instructions[:] = 0
        #     maneuver_processed = 0
        #     for maneuver in sm["navInstruction"].allManeuvers:
        #         distance_idx = 25 + int(maneuver.distance / 20)
        #         direction_idx = 0
        #         if maneuver.modifier in ("left", "slight left", "sharp left"):
        #             direction_idx = 1
        #         if maneuver.modifier in ("right", "slight right", "sharp right"):
        #             direction_idx = 2
        #         if 0 <= distance_idx < 50:
        #             final_idx = distance_idx * 3 + direction_idx
        #             nav_instructions[final_idx] = 1
        #             maneuver_processed += 1

        # # tracked dropped frames
        # vipc_dropped_frames = max(0, meta_main.frame_id - last_vipc_frame_id - 1)
        # if run_count < 10:  # let frame drops warm up
        #     frame_dropped_filter.x = 0.0
        # run_count = run_count + 1

        # prepare_only = vipc_dropped_frames > 0
        # if prepare_only:
        #     cloudlog.error(
        #         f"skipping E2E model eval. Dropped {vipc_dropped_frames} frames"
        #     )

        # inputs: Dict[str, np.ndarray] = {
        #     "carState": sm["carState"],
        #     "nav_instructions": nav_instructions,
        # }

        # mt1 = time.perf_counter()
        # model_output = model.run(buf_main, buf_extra, inputs)
        # mt2 = time.perf_counter()
        # model_execution_time = mt2 - mt1

        # if model_output is not None:
        #     cloudlog.debug(f"E2E model execution time: {model_execution_time:.4f}s")

        #     try:
        #         pred_vEgo = model_output["pred_vEgo"]
        #         pred_aEgo = model_output["pred_aEgo"]
        #         pred_steeringAngleDeg = model_output["pred_steeringAngleDeg"]
        #         vEgos_plan = model_output.get("vEgos_plan", [])

        #         cloudlog.debug("E2E ONNX model predictions")
        #         cloudlog.debug(f"steer: {pred_steeringAngleDeg:.6f} Deg")
        #         cloudlog.debug(f"acc: {pred_aEgo:.6f} m/sÂ², vel: {pred_vEgo:.6f} m/s")
        #         cloudlog.debug(f"execTime: {model_execution_time:.3f}ms")

        #         # è©³ç´°ãƒ‡ãƒãƒƒã‚°: ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›å€¤ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚‚è¨˜éŒ²
        #         debug_msg = f"steer={pred_steeringAngleDeg:.6f}, acc={pred_aEgo:.6f}, vel={pred_vEgo:.6f}, execTime={model_execution_time:.3f}ms"
        #         import time as time_module

        #         with open("/tmp/e2e_model_output_debug.log", "a") as f:
        #             f.write(f"{time_module.time()}: {debug_msg}\n")

        #         # rlogã«è¨˜éŒ²ã™ã‚‹ãŸã‚ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡
        #         if pm is not None:
        #             import cereal.messaging as messaging

        #             # e2eOutputãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        #             e2e_out_msg = messaging.new_message("e2eOutput")
        #             e2e_out_msg.e2eOutput.aEgo = pred_aEgo
        #             e2e_out_msg.e2eOutput.vEgo = pred_vEgo
        #             e2e_out_msg.e2eOutput.steeringAngleDeg = pred_steeringAngleDeg
        #             e2e_out_msg.e2eOutput.vEgoPlans = vEgos_plan
        #             e2e_out_msg.e2eOutput.timestamp = int(time.time_ns())
        #             e2e_out_msg.e2eOutput.isValid = True
        #             # é‡è¦: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ¬ãƒ™ãƒ«ã®validãƒ•ãƒ©ã‚°ã‚‚è¨­å®š
        #             e2e_out_msg.valid = True
        #             pm.send("e2eOutput", e2e_out_msg)

        #         # E2Eæ›´æ–°æ™‚é–“ã‚’è¨˜éŒ²
        #         last_e2e_update_time = current_time

        #     except Exception as e:
        #         cloudlog.error(f"Error processing E2E model output: {e}")
        #         import traceback

        #         cloudlog.error(f"E2E error traceback: {traceback.format_exc()}")

        #         # ã‚¨ãƒ©ãƒ¼æ™‚ã§ã‚‚ç„¡åŠ¹ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡
        #         try:
        #             e2e_out_msg = messaging.new_message("e2eOutput")
        #             e2e_out_msg.e2eOutput.aEgo = 0.0
        #             e2e_out_msg.e2eOutput.vEgo = 0.0
        #             e2e_out_msg.e2eOutput.steeringAngleDeg = 0.0
        #             e2e_out_msg.e2eOutput.vEgoPlans = [0.0] * 10
        #             e2e_out_msg.e2eOutput.timestamp = int(time.time_ns())
        #             e2e_out_msg.e2eOutput.isValid = False
        #             # ã‚¨ãƒ©ãƒ¼æ™‚: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ¬ãƒ™ãƒ«ã®validã‚‚ç„¡åŠ¹ã«è¨­å®š
        #             e2e_out_msg.valid = False
        #             pm.send("e2eOutput", e2e_out_msg)
        #             cloudlog.debug("E2E error: sent invalid message")
        #         except Exception as msg_error:
        #             cloudlog.error(f"Failed to send error message: {msg_error}")

        # # ãƒ•ãƒ¬ãƒ¼ãƒ IDã®æ›´æ–°ï¼ˆæ¬¡å›ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‰ãƒ­ãƒƒãƒ—æ¤œå‡ºç”¨ï¼‰
        # last_vipc_frame_id = meta_main.frame_id


# ===== ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œéƒ¨ =====
if __name__ == "__main__":
    """
    E2Eãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ¼ãƒ¢ãƒ³ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ

    ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°:
      --demo: ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ï¼ˆCarParamsã‚’è‡ªå‹•ç”Ÿæˆã€å®Ÿè»Šãªã—ã§ãƒ†ã‚¹ãƒˆå¯èƒ½ï¼‰

    å®Ÿè¡Œä¾‹:
      python selfdrive/modeld/e2emodeld.py          # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰
      python selfdrive/modeld/e2emodeld.py --demo   # ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰
    """
    try:
        # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®è§£æ
        import argparse

        parser = argparse.ArgumentParser(description="E2Eè‡ªå‹•é‹è»¢ãƒ¢ãƒ‡ãƒ«å®Ÿè¡Œãƒ‡ãƒ¼ãƒ¢ãƒ³")
        parser.add_argument(
            "--demo",
            action="store_true",
            help="ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ï¼ˆCarParamsè‡ªå‹•ç”Ÿæˆã€å®Ÿè»Šæ¥ç¶šä¸è¦ï¼‰",
        )
        args = parser.parse_args()

        # ãƒ¡ã‚¤ãƒ³é–¢æ•°ã®å®Ÿè¡Œ
        main(demo=args.demo)

    except KeyboardInterrupt:
        # Ctrl+Cã«ã‚ˆã‚‹æ­£å¸¸çµ‚äº†
        cloudlog.warning(f"child {PROCESS_NAME} got SIGINT")
    except Exception:
        # äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ã®å ´åˆã€Sentryã«é€ä¿¡ã—ã¦å†ç™ºç”Ÿ
        sentry.capture_exception()
        raise
